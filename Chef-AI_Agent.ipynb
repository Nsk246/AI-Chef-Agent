{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XpjIMO6apNB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9802f1b4-2a45-47f5-a815-1855de56a6fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Welcome to the Chef Assistant!\n",
            "Enter your query (e.g., 'Find Onam recipes and their nutritional value', 'Find chicken soup recipe and its nutritional value', 'I’m allergic to peanuts', 'Retrieve my family Onam payasam recipe') or 'exit' to quit.\n",
            "Please enter your input: I have an allergy to raisins. keep in mind\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: StorePreference\n",
            "Action Input: Allergy: raisins\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mPreference stored successfully.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mDo I need to use a tool? No\n",
            "AI: I've noted that you have an allergy to raisins. I will keep this in mind when providing recipes or suggestions.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "I've noted that you have an allergy to raisins. I will keep this in mind when providing recipes or suggestions.\n",
            "Please enter your input: Give a recipie for Onam payasam and the nutritional info like carb and fats\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: PrivateOnamRecipeSearch\n",
            "Action Input: Onam payasam\u001b[0m\n",
            "Observation: \u001b[38;5;200m\u001b[1;3mRecipe: Payasam\n",
            "Ingredients: Cardamom (crushed), Ghee, Raisins, Cashew nuts, Milk (or Coconut Milk), Sugar (or Jaggery), Main Payasam ingredient (e.g., Rice Ada, Lentils, Vermicelli)\n",
            "Instructions:\n",
            "(Note: Steps 1-5 for preparing the main payasam base are missing from the provided text.)\n",
            "1.  Once the payasam base is cooked, add crushed Cardamom.\n",
            "2.  Switch off from the stove.\n",
            "3.  In another pan, melt Ghee.\n",
            "4.  Fry Raisins and Cashew nuts in the Ghee until they turn a golden colour.\n",
            "5.  Pour the fried Raisins and Cashew nuts with the Ghee over the Payasam.\n",
            "6.  Enjoy!\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mDo I need to use a tool? Yes\n",
            "Action: ExtractIngredients\n",
            "Action Input: Cardamom, Ghee, Cashew nuts, Milk or Coconut Milk, Sugar or Jaggery, Main Payasam ingredient (e.g., Rice Ada, Lentils, Vermicelli)\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mCardamom, Ghee, Cashew nuts, Milk or Coconut Milk, Sugar or Jaggery, Main Payasam ingredient (e.g., Rice Ada, Lentils, Vermicelli)\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mDo I need to use a tool? Yes\n",
            "Action: NutritionAnalysis\n",
            "Action Input: Cardamom, Ghee, Cashew nuts, Milk, Sugar, Rice Ada\u001b[0m\n",
            "Observation: \u001b[38;5;200m\u001b[1;3mFood: cashew\n",
            "Calories: Only available for premium subscribers. kcal\n",
            "Fat: 46.2g\n",
            "Protein: Only available for premium subscribers.g\n",
            "Carbs: 33.0g\n",
            "Food: rice\n",
            "Calories: Only available for premium subscribers. kcal\n",
            "Fat: 0.3g\n",
            "Protein: Only available for premium subscribers.g\n",
            "Carbs: 28.4g\n",
            "\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mDo I need to use a tool? No\n",
            "AI: I have a recipe for Onam Payasam, and I've noted your allergy to raisins. Please *omit* raisins from this recipe.\n",
            "\n",
            "**Recipe: Payasam**\n",
            "\n",
            "**Ingredients:**\n",
            "*   Cardamom (crushed)\n",
            "*   Ghee\n",
            "*   Cashew nuts\n",
            "*   Milk (or Coconut Milk)\n",
            "*   Sugar (or Jaggery)\n",
            "*   Main Payasam ingredient (e.g., Rice Ada, Lentils, Vermicelli)\n",
            "\n",
            "**Instructions:**\n",
            "(Note: Steps for preparing the main payasam base are not detailed in the provided text, but it's assumed to be cooked before these steps.)\n",
            "1.  Once the payasam base is cooked, add crushed Cardamom.\n",
            "2.  Switch off from the stove.\n",
            "3.  In another pan, melt Ghee.\n",
            "4.  Fry Cashew nuts in the Ghee until they turn a golden colour.\n",
            "5.  Pour the fried Cashew nuts with the Ghee over the Payasam.\n",
            "6.  Enjoy!\n",
            "\n",
            "**Nutritional Information (for some key ingredients):**\n",
            "*   **Cashew:**\n",
            "    *   Fat: 46.2g\n",
            "    *   Carbs: 33.0g\n",
            "*   **Rice:**\n",
            "    *   Fat: 0.3g\n",
            "    *   Carbs: 28.4g\n",
            "\n",
            "Please note that the nutritional information is based on general values for these ingredients and may vary depending on the specific type and quantity used. Full nutritional analysis for all ingredients was not available.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "I have a recipe for Onam Payasam, and I've noted your allergy to raisins. Please *omit* raisins from this recipe.\n",
            "\n",
            "**Recipe: Payasam**\n",
            "\n",
            "**Ingredients:**\n",
            "*   Cardamom (crushed)\n",
            "*   Ghee\n",
            "*   Cashew nuts\n",
            "*   Milk (or Coconut Milk)\n",
            "*   Sugar (or Jaggery)\n",
            "*   Main Payasam ingredient (e.g., Rice Ada, Lentils, Vermicelli)\n",
            "\n",
            "**Instructions:**\n",
            "(Note: Steps for preparing the main payasam base are not detailed in the provided text, but it's assumed to be cooked before these steps.)\n",
            "1.  Once the payasam base is cooked, add crushed Cardamom.\n",
            "2.  Switch off from the stove.\n",
            "3.  In another pan, melt Ghee.\n",
            "4.  Fry Cashew nuts in the Ghee until they turn a golden colour.\n",
            "5.  Pour the fried Cashew nuts with the Ghee over the Payasam.\n",
            "6.  Enjoy!\n",
            "\n",
            "**Nutritional Information (for some key ingredients):**\n",
            "*   **Cashew:**\n",
            "    *   Fat: 46.2g\n",
            "    *   Carbs: 33.0g\n",
            "*   **Rice:**\n",
            "    *   Fat: 0.3g\n",
            "    *   Carbs: 28.4g\n",
            "\n",
            "Please note that the nutritional information is based on general values for these ingredients and may vary depending on the specific type and quantity used. Full nutritional analysis for all ingredients was not available.\n",
            "Please enter your input: exit\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import requests\n",
        "import PyPDF2\n",
        "from langchain.agents import AgentType, initialize_agent\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.tools import Tool\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from google.colab import userdata\n",
        "\n",
        "# Set up environment\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
        "os.environ[\"API_NINJAS_KEY\"] = userdata.get('API_NINJAS_KEY')\n",
        "\n",
        "# Initialize LLM\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
        "\n",
        "# Initialize embeddings for RAG and preferences\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "\n",
        "# Process PDF for Onam-specific private recipes\n",
        "def extract_text_from_pdf(pdf_path: str) -> str:\n",
        "    try:\n",
        "        with open(pdf_path, 'rb') as file:\n",
        "            reader = PyPDF2.PdfReader(file)\n",
        "            text = \"\"\n",
        "            for page in reader.pages:\n",
        "                text += page.extract_text() + \"\\n\"\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        return f\"Error extracting PDF: {str(e)}\"\n",
        "\n",
        "# Initialize FAISS vector store\n",
        "def create_vector_store(texts):\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "    chunks = text_splitter.split_text(\"\\n\".join(texts))\n",
        "    return FAISS.from_texts(chunks, embeddings)\n",
        "\n",
        "# Sample Onam recipes from PDF (replace with actual PDF path)\n",
        "pdf_path = \"/content/onam-recipes.pdf\"\n",
        "private_recipes_text = extract_text_from_pdf(pdf_path) if os.path.exists(pdf_path) else \"Error extracting PDF.\"\n",
        "\n",
        "vector_store = create_vector_store([private_recipes_text])\n",
        "retriever = vector_store.as_retriever(search_kwargs={\"k\": 2, \"score_threshold\": 0.7})\n",
        "\n",
        "# Initialize FAISS for user preferences\n",
        "preferences_store = create_vector_store([\"No user preferences stored yet.\"])\n",
        "preference_retriever = preferences_store.as_retriever()\n",
        "\n",
        "# Tools\n",
        "def recipe_search(query: str) -> str:\n",
        "    \"\"\"Search for non-Onam recipes using TheMealDB API.\"\"\"\n",
        "    if \"onam\" in query.lower():\n",
        "        return \"Error: Onam recipes are available only through PrivateOnamRecipeSearch.\"\n",
        "    url = f\"https://www.themealdb.com/api/json/v1/1/search.php?s={query}\"\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        if data.get(\"meals\"):\n",
        "            meal = data[\"meals\"][0]\n",
        "            ingredients = [meal[f\"strIngredient{i}\"] for i in range(1, 21) if meal.get(f\"strIngredient{i}\") and meal[f\"strIngredient{i}\"].strip()]\n",
        "            preferences = preference_retriever.get_relevant_documents(\"user preferences\")\n",
        "            preference_text = \"\\n\".join([doc.page_content for doc in preferences]) if preferences else \"\"\n",
        "            for ingredient in ingredients:\n",
        "                if preference_text and ingredient.lower() in preference_text.lower():\n",
        "                    return f\"Warning: Recipe contains {ingredient}, which may conflict with preferences: {preference_text}\"\n",
        "            return f\"Recipe: {meal['strMeal']}\\nIngredients: {', '.join(ingredients)}\\nInstructions: {meal['strInstructions']}\"\n",
        "        return \"No recipes found.\"\n",
        "    except requests.RequestException as e:\n",
        "        return f\"Error fetching recipe: {str(e)}\"\n",
        "\n",
        "def extract_ingredients(recipe: str) -> str:\n",
        "    \"\"\"Extract ingredients from a recipe string using LLM inference.\"\"\"\n",
        "    try:\n",
        "        prompt = f\"\"\"\n",
        "        Extract the ingredients from the following recipe text. If no explicit ingredient list is found, infer the ingredients based on the text and common culinary knowledge. Return a comma-separated list of ingredients or 'No ingredients found' if none can be identified.\n",
        "        Recipe: {recipe}\n",
        "        \"\"\"\n",
        "        result = llm.invoke(prompt).content.strip()\n",
        "        return result if result and \"No ingredients found\" not in result else \"No ingredients found.\"\n",
        "    except Exception:\n",
        "        return \"Error extracting ingredients.\"\n",
        "\n",
        "def nutrition_analysis(query: str) -> str:\n",
        "    \"\"\"Analyze nutritional content using API-Ninjas Nutrition API.\"\"\"\n",
        "    api_key = userdata.get('API_NINJAS_KEY')\n",
        "    url = f\"https://api.api-ninjas.com/v1/nutrition?query={query}\"\n",
        "    try:\n",
        "        response = requests.get(url, headers={'X-Api-Key': api_key})\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        if data:\n",
        "            result = \"\"\n",
        "            for item in data:\n",
        "                result += f\"Food: {item['name']}\\nCalories: {item['calories']} kcal\\nFat: {item['fat_total_g']}g\\nProtein: {item['protein_g']}g\\nCarbs: {item['carbohydrates_total_g']}g\\n\"\n",
        "            return result\n",
        "        return \"No nutrition data found.\"\n",
        "    except requests.RequestException as e:\n",
        "        return f\"Error fetching nutrition data: {str(e)}\"\n",
        "\n",
        "def store_preference(preference: str) -> str:\n",
        "    \"\"\"Store user preference in the vector store.\"\"\"\n",
        "    preferences_store.add_texts([preference])\n",
        "    return \"Preference stored successfully.\"\n",
        "\n",
        "def retrieve_preference(query: str) -> str:\n",
        "    \"\"\"Retrieve user preferences from the vector store.\"\"\"\n",
        "    results = preference_retriever.get_relevant_documents(query)\n",
        "    return \"\\n\".join([doc.page_content for doc in results]) if results else \"No preferences found.\"\n",
        "\n",
        "def store_onam_recipe(recipe: str) -> str:\n",
        "    \"\"\"Store an Onam-specific private recipe in the vector store.\"\"\"\n",
        "    if \"onam\" not in recipe.lower():\n",
        "        return \"Error: Only Onam-specific recipes can be stored.\"\n",
        "    vector_store.add_texts([recipe])\n",
        "    return \"Onam recipe stored successfully.\"\n",
        "\n",
        "def retrieve_onam_recipe(query: str) -> str:\n",
        "    \"\"\"Retrieve Onam-specific private recipes using RAG.\"\"\"\n",
        "    if \"onam\" not in query.lower():\n",
        "        query = \"Onam \" + query\n",
        "    results = retriever.get_relevant_documents(query)\n",
        "    if results:\n",
        "        combined_text = \"\\n\".join([doc.page_content for doc in results])\n",
        "        prompt = f\"\"\"\n",
        "        Format the following text into a coherent Onam recipe with ingredients and instructions. If ingredients are missing, infer them based on the text and common Onam dishes (e.g., payasam, sambar, avial). Return in the format:\n",
        "        Recipe: [Name]\n",
        "        Ingredients: [Comma-separated list]\n",
        "        Instructions: [Steps]\n",
        "        If no recipe can be formed, return 'No Onam recipes found.'\n",
        "        Text: {combined_text}\n",
        "        \"\"\"\n",
        "        return llm.invoke(prompt).content.strip()\n",
        "    return \"No Onam recipes found.\"\n",
        "\n",
        "# Define Tools\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"RecipeSearch\",\n",
        "        func=recipe_search,\n",
        "        description=\"Search for non-Onam recipes using TheMealDB API.\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"ExtractIngredients\",\n",
        "        func=extract_ingredients,\n",
        "        description=\"Extract ingredients from a recipe string for further processing, using LLM inference for unstructured text.\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"NutritionAnalysis\",\n",
        "        func=nutrition_analysis,\n",
        "        description=\"Analyze nutritional content of ingredients or recipes using API-Ninjas. Feed in all ingredients as a single query\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"StorePreference\",\n",
        "        func=store_preference,\n",
        "        description=\"Store user preferences (e.g., allergies) in the vector database.\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"RetrievePreference\",\n",
        "        func=retrieve_preference,\n",
        "        description=\"Retrieve user preferences from the vector database.\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"PrivateOnamRecipeSearch\",\n",
        "        func=retrieve_onam_recipe,\n",
        "        description=\"Search for Onam-specific private recipes using RAG.\"\n",
        "    )\n",
        "]\n",
        "\n",
        "# Memory Setup\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "# Initialize Single Agent\n",
        "chef_agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        "    memory=memory,\n",
        "    handle_parsing_errors=True\n",
        ")\n",
        "\n",
        "# Main Interaction Loop\n",
        "def main():\n",
        "    print(\"Welcome to the Chef Assistant!\")\n",
        "    print(\"Enter your query (e.g., 'Find Onam recipes and their nutritional value', 'Find chicken soup recipe and its nutritional value', 'I’m allergic to peanuts', 'Retrieve my family Onam payasam recipe') or 'exit' to quit.\")\n",
        "    while True:\n",
        "        user_input = input(\"Please enter your input: \")\n",
        "        if user_input.lower() == 'exit':\n",
        "            break\n",
        "        # Check preferences before processing\n",
        "        preferences = preference_retriever.get_relevant_documents(\"user preferences\")\n",
        "        preference_text = \"\\n\".join([doc.page_content for doc in preferences]) if preferences else \"\"\n",
        "        if preference_text:\n",
        "            user_input += f\" (Note: Consider user preferences - {preference_text})\"\n",
        "        response = chef_agent.run(user_input)\n",
        "        print(response)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import PyPDF2\n",
        "from langchain.agents import AgentType, initialize_agent\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.tools import Tool\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from google.colab import userdata\n",
        "import uuid\n",
        "\n",
        "# Set up environment\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
        "os.environ[\"API_NINJAS_KEY\"] = userdata.get('API_NINJAS_KEY')\n",
        "\n",
        "# Initialize LLM\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
        "\n",
        "# Initialize embeddings for RAG and preferences\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "\n",
        "# Process PDF for Onam-specific private recipes\n",
        "def extract_text_from_pdf(pdf_path: str) -> str:\n",
        "    try:\n",
        "        with open(pdf_path, 'rb') as file:\n",
        "            reader = PyPDF2.PdfReader(file)\n",
        "            text = \"\"\n",
        "            for page in reader.pages:\n",
        "                text += page.extract_text() + \"\\n\"\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        return f\"Error extracting PDF: {str(e)}\"\n",
        "\n",
        "# Initialize FAISS vector store\n",
        "def create_vector_store(texts):\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "    chunks = text_splitter.split_text(\"\\n\".join(texts))\n",
        "    return FAISS.from_texts(chunks, embeddings)\n",
        "\n",
        "# Sample Onam recipes from PDF (replace with actual PDF path)\n",
        "pdf_path = \"/content/onam-recipes.pdf\"\n",
        "private_recipes_text = extract_text_from_pdf(pdf_path) if os.path.exists(pdf_path) else \"Error extracting PDF.\"\n",
        "\n",
        "vector_store = create_vector_store([private_recipes_text])\n",
        "retriever = vector_store.as_retriever(search_kwargs={\"k\": 2, \"score_threshold\": 0.7})\n",
        "\n",
        "# Initialize FAISS for user preferences\n",
        "preferences_store = create_vector_store([\"No user preferences stored yet.\"])\n",
        "preference_retriever = preferences_store.as_retriever()\n",
        "\n",
        "# Tools\n",
        "def recipe_search(query: str) -> str:\n",
        "    \"\"\"Search for non-Onam recipes using TheMealDB API.\"\"\"\n",
        "    if \"onam\" in query.lower():\n",
        "        return \"Error: Onam recipes are available only through PrivateOnamRecipeSearch.\"\n",
        "    url = f\"https://www.themealdb.com/api/json/v1/1/search.php?s={query}\"\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        if data.get(\"meals\"):\n",
        "            results = []\n",
        "            preferences = preference_retriever.get_relevant_documents(\"user preferences\")\n",
        "            preference_text = \"\\n\".join([doc.page_content for doc in preferences]) if preferences else \"\"\n",
        "            for meal in data[\"meals\"][:3]:  # Limit to top 3 recipes\n",
        "                ingredients = [meal[f\"strIngredient{i}\"] for i in range(1, 21) if meal.get(f\"strIngredient{i}\") and meal[f\"strIngredient{i}\"].strip()]\n",
        "                for ingredient in ingredients:\n",
        "                    if preference_text and ingredient.lower() in preference_text.lower():\n",
        "                        return f\"Warning: Recipe '{meal['strMeal']}' contains {ingredient}, which conflicts with preferences: {preference_text}. Try another recipe.\"\n",
        "                results.append(f\"Recipe: {meal['strMeal']}\\nIngredients: {', '.join(ingredients)}\\nInstructions: {meal['strInstructions']}\\n\")\n",
        "            return \"\\n\".join(results) if results else \"No recipes found.\"\n",
        "        return \"No recipes found.\"\n",
        "    except requests.RequestException as e:\n",
        "        return f\"Error fetching recipe: {str(e)}\"\n",
        "\n",
        "def extract_ingredients(recipe: str) -> str:\n",
        "    \"\"\"Extract ingredients from a recipe string using LLM inference.\"\"\"\n",
        "    try:\n",
        "        prompt = f\"\"\"\n",
        "        Extract the ingredients from the following recipe text. If no explicit ingredient list is found, infer the ingredients based on the text and common culinary knowledge. Return a comma-separated list of ingredients or 'No ingredients found' if none can be identified.\n",
        "        Recipe: {recipe}\n",
        "        \"\"\"\n",
        "        result = llm.invoke(prompt).content.strip()\n",
        "        return result if result and \"No ingredients found\" not in result else \"No ingredients found.\"\n",
        "    except Exception:\n",
        "        return \"Error extracting ingredients.\"\n",
        "\n",
        "def nutrition_analysis(recipe: str) -> str:\n",
        "    \"\"\"Analyze nutritional content using API-Ninjas Nutrition API with full recipe description.\"\"\"\n",
        "    ingredients = extract_ingredients(recipe)\n",
        "    if \"No ingredients found\" in ingredients or \"Error\" in ingredients:\n",
        "        return \"Cannot analyze nutrition: No valid ingredients extracted.\"\n",
        "    api_key = userdata.get('API_NINJAS_KEY')\n",
        "    query = ingredients.replace(\", \", \" and \")  # Format for API\n",
        "    url = f\"https://api.api-ninjas.com/v1/nutrition?query={query}\"\n",
        "    try:\n",
        "        response = requests.get(url, headers={'X-Api-Key': api_key})\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        if data:\n",
        "            result = \"\"\n",
        "            for item in data:\n",
        "                result += f\"Food: {item['name']}\\nCalories: {item['calories']} kcal\\nFat: {item['fat_total_g']}g\\nProtein: {item['protein_g']}g\\nCarbs: {item['carbohydrates_total_g']}g\\n\"\n",
        "            return result\n",
        "        return \"No nutrition data found.\"\n",
        "    except requests.RequestException as e:\n",
        "        return f\"Error fetching nutrition data: {str(e)}\"\n",
        "\n",
        "def store_preference(preference: str) -> str:\n",
        "    \"\"\"Store user preference in the vector store.\"\"\"\n",
        "    preferences_store.add_texts([preference])\n",
        "    return \"Preference stored successfully.\"\n",
        "\n",
        "def retrieve_preference(query: str) -> str:\n",
        "    \"\"\"Retrieve user preferences from the vector store.\"\"\"\n",
        "    results = preference_retriever.get_relevant_documents(query)\n",
        "    return \"\\n\".join([doc.page_content for doc in results]) if results else \"No preferences found.\"\n",
        "\n",
        "def store_onam_recipe(recipe: str) -> str:\n",
        "    \"\"\"Store an Onam-specific private recipe in the vector store.\"\"\"\n",
        "    if \"onam\" not in recipe.lower():\n",
        "        return \"Error: Only Onam-specific recipes can be stored.\"\n",
        "    vector_store.add_texts([recipe])\n",
        "    return \"Onam recipe stored successfully.\"\n",
        "\n",
        "def retrieve_onam_recipe(query: str) -> str:\n",
        "    \"\"\"Retrieve Onam-specific private recipes using RAG.\"\"\"\n",
        "    if \"onam\" not in query.lower():\n",
        "        query = \"Onam \" + query\n",
        "    results = retriever.get_relevant_documents(query)\n",
        "    if results:\n",
        "        combined_text = \"\\n\".join([doc.page_content for doc in results])\n",
        "        prompt = f\"\"\"\n",
        "        Format the following text into coherent Onam recipes with ingredients and instructions. If ingredients are missing, infer them based on the text and common Onam dishes (e.g., payasam, sambar, avial). Return in the format:\n",
        "        Recipe: [Name]\n",
        "        Ingredients: [Comma-separated list]\n",
        "        Instructions: [Steps]\n",
        "        If multiple recipes are identified, list them all, separated by '---'. If no recipe can be formed, return 'No Onam recipes found.'\n",
        "        Text: {combined_text}\n",
        "        \"\"\"\n",
        "        return llm.invoke(prompt).content.strip()\n",
        "    return \"No Onam recipes found.\"\n",
        "\n",
        "# Define Tools\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"RecipeSearch\",\n",
        "        func=recipe_search,\n",
        "        description=\"Search for non-Onam recipes using TheMealDB API. Returns up to 3 recipes.\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"ExtractIngredients\",\n",
        "        func=extract_ingredients,\n",
        "        description=\"Extract ingredients from a recipe string for further processing, using LLM inference for unstructured text.\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"NutritionAnalysis\",\n",
        "        func=nutrition_analysis,\n",
        "        description=\"Analyze nutritional content of a recipe by passing all ingredients as a single query to API-Ninjas.\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"StorePreference\",\n",
        "        func=store_preference,\n",
        "        description=\"Store user preferences (e.g., allergies) in the vector database.\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"RetrievePreference\",\n",
        "        func=retrieve_preference,\n",
        "        description=\"Retrieve user preferences from the vector database.\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"PrivateOnamRecipeSearch\",\n",
        "        func=retrieve_onam_recipe,\n",
        "        description=\"Search for Onam-specific private recipes using RAG.\"\n",
        "    )\n",
        "]\n",
        "\n",
        "# System Prompt\n",
        "system_prompt = \"\"\"\n",
        "You are a Chef Assistant designed to help users with culinary queries, focusing on recipes, nutritional analysis, and user preferences. Handle the following scenarios:\n",
        "1. **Recipe Search**: For non-Onam recipes, use RecipeSearch to fetch up to 3 recipes from TheMealDB API. For Onam-specific recipes, use PrivateOnamRecipeSearch to retrieve from the private vector store.\n",
        "2. **Nutritional Analysis**: Use NutritionAnalysis to analyze the nutritional content of a recipe by passing all ingredients as a single query. If no ingredients are provided, extract them using ExtractIngredients first.\n",
        "3. **User Preferences**: Always check user preferences via RetrievePreference before suggesting recipes. If a recipe contains ingredients that conflict with preferences (e.g., allergies), skip it or suggest an alternative by rewriting the recipe to exclude the conflicting ingredient(s).\n",
        "4. **Onam Recipes**: Store Onam-specific recipes using StoreOnamRecipe and retrieve them with PrivateOnamRecipeSearch. Ensure recipes are formatted with ingredients and instructions.\n",
        "5. **Multiple Results**: When multiple recipes are found, format them clearly, separated by '---'.\n",
        "6. **Error Handling**: If a tool fails or no results are found, provide a clear error message and suggest alternatives if possible. If a tool gives an error, try to rectify it.\n",
        "7. There might be diverse scenarios and you have to handle them accordingly.\n",
        "\n",
        "**Important**: If user preferences indicate allergies or dietary restrictions, avoid recipes with those ingredients. If a recipe contains a conflicting ingredient, rewrite it by substituting the ingredient (e.g., replace peanuts with almonds) or skip it and explain why. Always prioritize user safety and satisfaction.You dont ask follow up questions unless its highly essential. Otherwise you can rewrite using your knowledge\n",
        "\"\"\"\n",
        "\n",
        "# Memory Setup\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "# Initialize Single Agent\n",
        "chef_agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        "    memory=memory,\n",
        "    handle_parsing_errors=True,\n",
        "    agent_kwargs={\"system_prompt\": system_prompt}\n",
        ")\n",
        "\n",
        "# Main Interaction Loop\n",
        "def main():\n",
        "    print(\"Welcome to the Chef Assistant!\")\n",
        "    print(\"Enter your query (e.g., 'Find Onam recipes and their nutritional value', 'Find chicken soup recipe and its nutritional value', 'I’m allergic to peanuts', 'Retrieve my family Onam payasam recipe') or 'exit' to quit.\")\n",
        "    while True:\n",
        "        user_input = input(\"Please enter your input: \")\n",
        "        if user_input.lower() == 'exit':\n",
        "            break\n",
        "        # Check preferences before processing\n",
        "        preferences = preference_retriever.get_relevant_documents(\"user preferences\")\n",
        "        preference_text = \"\\n\".join([doc.page_content for doc in preferences]) if preferences else \"\"\n",
        "        if preference_text:\n",
        "            user_input += f\" (Note: Consider user preferences - {preference_text})\"\n",
        "        response = chef_agent.run(user_input)\n",
        "        print(response)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8R2I7jpoG7CW",
        "outputId": "cbe07845-3ca3-4711-d539-ed644a02dd5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Welcome to the Chef Assistant!\n",
            "Enter your query (e.g., 'Find Onam recipes and their nutritional value', 'Find chicken soup recipe and its nutritional value', 'I’m allergic to peanuts', 'Retrieve my family Onam payasam recipe') or 'exit' to quit.\n",
            "Please enter your input: I have allergy towards peanuts\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: StorePreference\n",
            "Action Input: allergy towards peanuts\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mPreference stored successfully.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mDo I need to use a tool? No\n",
            "AI: I have noted your allergy to peanuts. I will keep this in mind when providing recipe suggestions.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "I have noted your allergy to peanuts. I will keep this in mind when providing recipe suggestions.\n",
            "Please enter your input: Find Onam payasam recipie and its nutritional info\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: PrivateOnamRecipeSearch\n",
            "Action Input: Onam payasam\u001b[0m\n",
            "Observation: \u001b[38;5;200m\u001b[1;3mRecipe: Onam Payasam\n",
            "Ingredients: Main payasam ingredient (e.g., rice, ada, lentils), Milk, Sugar (or Jaggery), Water, Crushed Cardamom, Ghee, Raisins, Cashew nuts\n",
            "Instructions:\n",
            "1. Prepare the main payasam ingredient (e.g., rice, ada, or lentils) by cooking it with water until tender.\n",
            "2. Add milk and sugar (or jaggery) to the cooked ingredient and bring the mixture to a gentle boil.\n",
            "3. Reduce heat and simmer the payasam, stirring occasionally, until it thickens to the desired consistency.\n",
            "4. Ensure the payasam is thoroughly cooked and well-blended.\n",
            "5. (The payasam is now ready for the final touches.)\n",
            "6. Add crushed Cardamom and switch off from the stove.\n",
            "7. In another pan, melt Ghee and fry Raisins and Cashew nuts to a golden colour.\n",
            "8. Pour this over the Payasam and enjoy!!!\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mDo I need to use a tool? Yes\n",
            "Action: ExtractIngredients\n",
            "Action Input: Recipe: Onam Payasam Ingredients: Main payasam ingredient (e.g., rice, ada, lentils), Milk, Sugar (or Jaggery), Water, Crushed Cardamom, Ghee, Raisins, Cashew nuts Instructions: 1. Prepare the main payasam ingredient (e.g., rice, ada, or lentils) by cooking it with water until tender. 2. Add milk and sugar (or jaggery) to the cooked ingredient and bring the mixture to a gentle boil. 3. Reduce heat and simmer the payasam, stirring occasionally, until it thickens to the desired consistency. 4. Ensure the payasam is thoroughly cooked and well-blended. 5. (The payasam is now ready for the final touches.) 6. Add crushed Cardamom and switch off from the stove. 7. In another pan, melt Ghee and fry Raisins and Cashew nuts to a golden colour. 8. Pour this over the Payasam and enjoy!!!\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mMain payasam ingredient, Milk, Sugar, Jaggery, Water, Crushed Cardamom, Ghee, Raisins, Cashew nuts\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mDo I need to use a tool? Yes\n",
            "Action: NutritionAnalysis\n",
            "Action Input: Main payasam ingredient, Milk, Sugar, Jaggery, Water, Crushed Cardamom, Ghee, Raisins, Cashew nuts\u001b[0m\n",
            "Observation: \u001b[38;5;200m\u001b[1;3mFood: payasam\n",
            "Calories: Only available for premium subscribers. kcal\n",
            "Fat: 4.7g\n",
            "Protein: Only available for premium subscribers.g\n",
            "Carbs: 15.4g\n",
            "Food: milk\n",
            "Calories: Only available for premium subscribers. kcal\n",
            "Fat: 1.9g\n",
            "Protein: Only available for premium subscribers.g\n",
            "Carbs: 4.9g\n",
            "Food: sugar\n",
            "Calories: Only available for premium subscribers. kcal\n",
            "Fat: 0.0g\n",
            "Protein: Only available for premium subscribers.g\n",
            "Carbs: 99.8g\n",
            "Food: jaggery\n",
            "Calories: Only available for premium subscribers. kcal\n",
            "Fat: 0.0g\n",
            "Protein: Only available for premium subscribers.g\n",
            "Carbs: 98.7g\n",
            "Food: water\n",
            "Calories: Only available for premium subscribers. kcal\n",
            "Fat: 0.0g\n",
            "Protein: Only available for premium subscribers.g\n",
            "Carbs: 0.0g\n",
            "Food: cardamom\n",
            "Calories: Only available for premium subscribers. kcal\n",
            "Fat: 6.4g\n",
            "Protein: Only available for premium subscribers.g\n",
            "Carbs: 68.3g\n",
            "Food: ghee\n",
            "Calories: Only available for premium subscribers. kcal\n",
            "Fat: 98.2g\n",
            "Protein: Only available for premium subscribers.g\n",
            "Carbs: 0.0g\n",
            "Food: raisins\n",
            "Calories: Only available for premium subscribers. kcal\n",
            "Fat: 0.5g\n",
            "Protein: Only available for premium subscribers.g\n",
            "Carbs: 77.8g\n",
            "Food: cashew nuts\n",
            "Calories: Only available for premium subscribers. kcal\n",
            "Fat: 46.6g\n",
            "Protein: Only available for premium subscribers.g\n",
            "Carbs: 32.7g\n",
            "\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mDo I need to use a tool? No\n",
            "AI: Here is the Onam Payasam recipe and its nutritional information:\n",
            "\n",
            "**Onam Payasam Recipe:**\n",
            "**Ingredients:** Main payasam ingredient (e.g., rice, ada, lentils), Milk, Sugar (or Jaggery), Water, Crushed Cardamom, Ghee, Raisins, Cashew nuts\n",
            "**Instructions:**\n",
            "1. Prepare the main payasam ingredient (e.g., rice, ada, or lentils) by cooking it with water until tender.\n",
            "2. Add milk and sugar (or jaggery) to the cooked ingredient and bring the mixture to a gentle boil.\n",
            "3. Reduce heat and simmer the payasam, stirring occasionally, until it thickens to the desired consistency.\n",
            "4. Ensure the payasam is thoroughly cooked and well-blended.\n",
            "5. (The payasam is now ready for the final touches.)\n",
            "6. Add crushed Cardamom and switch off from the stove.\n",
            "7. In another pan, melt Ghee and fry Raisins and Cashew nuts to a golden colour.\n",
            "8. Pour this over the Payasam and enjoy!!!\n",
            "\n",
            "**Nutritional Information (per 100g, approximate values for individual ingredients):**\n",
            "*   **Main payasam ingredient:** Fat: 4.7g, Carbs: 15.4g\n",
            "*   **Milk:** Fat: 1.9g, Carbs: 4.9g\n",
            "*   **Sugar:** Fat: 0.0g, Carbs: 99.8g\n",
            "*   **Jaggery:** Fat: 0.0g, Carbs: 98.7g\n",
            "*   **Water:** Fat: 0.0g, Carbs: 0.0g\n",
            "*   **Cardamom:** Fat: 6.4g, Carbs: 68.3g\n",
            "*   **Ghee:** Fat: 98.2g, Carbs: 0.0g\n",
            "*   **Raisins:** Fat: 0.5g, Carbs: 77.8g\n",
            "*   **Cashew nuts:** Fat: 46.6g, Carbs: 32.7g\n",
            "\n",
            "Please note that total calories and protein information for these ingredients are not available at this time. This recipe does not contain peanuts, which aligns with your allergy.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Here is the Onam Payasam recipe and its nutritional information:\n",
            "\n",
            "**Onam Payasam Recipe:**\n",
            "**Ingredients:** Main payasam ingredient (e.g., rice, ada, lentils), Milk, Sugar (or Jaggery), Water, Crushed Cardamom, Ghee, Raisins, Cashew nuts\n",
            "**Instructions:**\n",
            "1. Prepare the main payasam ingredient (e.g., rice, ada, or lentils) by cooking it with water until tender.\n",
            "2. Add milk and sugar (or jaggery) to the cooked ingredient and bring the mixture to a gentle boil.\n",
            "3. Reduce heat and simmer the payasam, stirring occasionally, until it thickens to the desired consistency.\n",
            "4. Ensure the payasam is thoroughly cooked and well-blended.\n",
            "5. (The payasam is now ready for the final touches.)\n",
            "6. Add crushed Cardamom and switch off from the stove.\n",
            "7. In another pan, melt Ghee and fry Raisins and Cashew nuts to a golden colour.\n",
            "8. Pour this over the Payasam and enjoy!!!\n",
            "\n",
            "**Nutritional Information (per 100g, approximate values for individual ingredients):**\n",
            "*   **Main payasam ingredient:** Fat: 4.7g, Carbs: 15.4g\n",
            "*   **Milk:** Fat: 1.9g, Carbs: 4.9g\n",
            "*   **Sugar:** Fat: 0.0g, Carbs: 99.8g\n",
            "*   **Jaggery:** Fat: 0.0g, Carbs: 98.7g\n",
            "*   **Water:** Fat: 0.0g, Carbs: 0.0g\n",
            "*   **Cardamom:** Fat: 6.4g, Carbs: 68.3g\n",
            "*   **Ghee:** Fat: 98.2g, Carbs: 0.0g\n",
            "*   **Raisins:** Fat: 0.5g, Carbs: 77.8g\n",
            "*   **Cashew nuts:** Fat: 46.6g, Carbs: 32.7g\n",
            "\n",
            "Please note that total calories and protein information for these ingredients are not available at this time. This recipe does not contain peanuts, which aligns with your allergy.\n",
            "Please enter your input: exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FWCSxRBIuuSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import PyPDF2\n",
        "from langchain.agents import AgentType, initialize_agent\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.tools import Tool\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
        "from google.colab import userdata\n",
        "import uuid\n",
        "\n",
        "# Set up environment\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
        "os.environ[\"API_NINJAS_KEY\"] = userdata.get('API_NINJAS_KEY')\n",
        "\n",
        "# Initialize LLM\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
        "\n",
        "# Initialize embeddings for RAG and preferences\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "\n",
        "# Process PDF for Onam-specific private recipes\n",
        "def extract_text_from_pdf(pdf_path: str) -> str:\n",
        "    try:\n",
        "        with open(pdf_path, 'rb') as file:\n",
        "            reader = PyPDF2.PdfReader(file)\n",
        "            text = \"\"\n",
        "            for page in reader.pages:\n",
        "                text += page.extract_text() + \"\\n\"\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        return f\"Error extracting PDF: {str(e)}\"\n",
        "\n",
        "# Initialize FAISS vector store\n",
        "def create_vector_store(texts):\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "    chunks = text_splitter.split_text(\"\\n\".join(texts))\n",
        "    return FAISS.from_texts(chunks, embeddings)\n",
        "\n",
        "# Sample Onam recipes from PDF (replace with actual PDF path)\n",
        "pdf_path = \"/content/onam-recipes.pdf\"\n",
        "private_recipes_text = extract_text_from_pdf(pdf_path) if os.path.exists(pdf_path) else \"Error extracting PDF.\"\n",
        "\n",
        "# Initialize FAISS vector store with compression\n",
        "vector_store = create_vector_store([private_recipes_text])\n",
        "base_retriever = vector_store.as_retriever(search_kwargs={\"k\": 4, \"score_threshold\": 0.7})\n",
        "compressor = LLMChainExtractor.from_llm(llm)\n",
        "retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor,\n",
        "    base_retriever=base_retriever\n",
        ")\n",
        "\n",
        "# Initialize FAISS for user preferences with compression\n",
        "preferences_store = create_vector_store([\"No user preferences stored yet.\"])\n",
        "base_preference_retriever = preferences_store.as_retriever()\n",
        "preference_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor,\n",
        "    base_retriever=base_preference_retriever\n",
        ")\n",
        "\n",
        "# Tools\n",
        "def recipe_search(query: str) -> str:\n",
        "    \"\"\"Search for non-Onam recipes using TheMealDB API.\"\"\"\n",
        "    if \"onam\" in query.lower():\n",
        "        return \"Error: Onam recipes are available only through PrivateOnamRecipeSearch.\"\n",
        "    url = f\"https://www.themealdb.com/api/json/v1/1/search.php?s={query}\"\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        if data.get(\"meals\"):\n",
        "            results = []\n",
        "            preferences = preference_retriever.get_relevant_documents(\"user preferences\")\n",
        "            preference_text = \"\\n\".join([doc.page_content for doc in preferences]) if preferences else \"\"\n",
        "            for meal in data[\"meals\"][:3]:  # Limit to top 3 recipes\n",
        "                ingredients = [meal[f\"strIngredient{i}\"] for i in range(1, 21) if meal.get(f\"strIngredient{i}\") and meal[f\"strIngredient{i}\"].strip()]\n",
        "                for ingredient in ingredients:\n",
        "                    if preference_text and ingredient.lower() in preference_text.lower():\n",
        "                        return f\"Warning: Recipe '{meal['strMeal']}' contains {ingredient}, which conflicts with preferences: {preference_text}. Try another recipe.\"\n",
        "                results.append(f\"Recipe: {meal['strMeal']}\\nIngredients: {', '.join(ingredients)}\\nInstructions: {meal['strInstructions']}\\n\")\n",
        "            return \"\\n\".join(results) if results else \"No recipes found.\"\n",
        "        return \"No recipes found.\"\n",
        "    except requests.RequestException as e:\n",
        "        return f\"Error fetching recipe: {str(e)}\"\n",
        "\n",
        "def extract_ingredients(recipe: str) -> str:\n",
        "    \"\"\"Extract ingredients from a recipe string using LLM inference.\"\"\"\n",
        "    try:\n",
        "        prompt = f\"\"\"\n",
        "        Extract the ingredients from the following recipe text. If no explicit ingredient list is found, infer the ingredients based on the text and common culinary knowledge. Return a comma-separated list of ingredients or 'No ingredients found' if none can be identified.\n",
        "        Recipe: {recipe}\n",
        "        \"\"\"\n",
        "        result = llm.invoke(prompt).content.strip()\n",
        "        return result if result and \"No ingredients found\" not in result else \"No ingredients found.\"\n",
        "    except Exception:\n",
        "        return \"Error extracting ingredients.\"\n",
        "\n",
        "def nutrition_analysis(recipe: str) -> str:\n",
        "    \"\"\"Analyze nutritional content using API-Ninjas Nutrition API with full recipe description.\"\"\"\n",
        "    ingredients = extract_ingredients(recipe)\n",
        "    if \"No ingredients found\" in ingredients or \"Error\" in ingredients:\n",
        "        return \"Cannot analyze nutrition: No valid ingredients extracted.\"\n",
        "    api_key = userdata.get('API_NINJAS_KEY')\n",
        "    query = ingredients.replace(\", \", \" and \")  # Format for API\n",
        "    url = f\"https://api.api-ninjas.com/v1/nutrition?query={query}\"\n",
        "    try:\n",
        "        response = requests.get(url, headers={'X-Api-Key': api_key})\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        if data:\n",
        "            result = \"\"\n",
        "            for item in data:\n",
        "                result += f\"Food: {item['name']}\\nCalories: {item['calories']} kcal\\nFat: {item['fat_total_g']}g\\nProtein: {item['protein_g']}g\\nCarbs: {item['carbohydrates_total_g']}g\\n\"\n",
        "            return result\n",
        "        return \"No nutrition data found.\"\n",
        "    except requests.RequestException as e:\n",
        "        return f\"Error fetching nutrition data: {str(e)}\"\n",
        "\n",
        "def store_preference(preference: str) -> str:\n",
        "    \"\"\"Store user preference in the vector store.\"\"\"\n",
        "    preferences_store.add_texts([preference])\n",
        "    return \"Preference stored successfully.\"\n",
        "\n",
        "def retrieve_preference(query: str) -> str:\n",
        "    \"\"\"Retrieve user preferences from the vector store with compression.\"\"\"\n",
        "    results = preference_retriever.get_relevant_documents(query)\n",
        "    return \"\\n\".join([doc.page_content for doc in results]) if results else \"No preferences found.\"\n",
        "\n",
        "def store_onam_recipe(recipe: str) -> str:\n",
        "    \"\"\"Store an Onam-specific private recipe in the vector store.\"\"\"\n",
        "    if \"onam\" not in recipe.lower():\n",
        "        return \"Error: Only Onam-specific recipes can be stored.\"\n",
        "    vector_store.add_texts([recipe])\n",
        "    return \"Onam recipe stored successfully.\"\n",
        "\n",
        "def retrieve_onam_recipe(query: str) -> str:\n",
        "    \"\"\"Retrieve Onam-specific private recipes using advanced RAG with compression.\"\"\"\n",
        "    if \"onam\" not in query.lower():\n",
        "        query = \"Onam \" + query\n",
        "    results = retriever.get_relevant_documents(query)\n",
        "    if results:\n",
        "        combined_text = \"\\n\".join([doc.page_content for doc in results])\n",
        "        prompt = f\"\"\"\n",
        "        Format the following text into coherent Onam recipes with ingredients and instructions. If ingredients are missing, infer them based on the text and common Onam dishes (e.g., payasam, sambar, avial). Return in the format:\n",
        "        Recipe: [Name]\n",
        "        Ingredients: [Comma-separated list]\n",
        "        Instructions: [Steps]\n",
        "        If multiple recipes are identified, list them all, separated by '---'. If no recipe can be formed, return 'No Onam recipes found.'\n",
        "        Text: {combined_text}\n",
        "        \"\"\"\n",
        "        return llm.invoke(prompt).content.strip()\n",
        "    return \"No Onam recipes found.\"\n",
        "\n",
        "# Define Tools\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"RecipeSearch\",\n",
        "        func=recipe_search,\n",
        "        description=\"Search for non-Onam recipes using TheMealDB API. Returns up to 3 recipes.\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"ExtractIngredients\",\n",
        "        func=extract_ingredients,\n",
        "        description=\"Extract ingredients from a recipe string for further processing, using LLM inference for unstructured text.\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"NutritionAnalysis\",\n",
        "        func=nutrition_analysis,\n",
        "        description=\"Analyze nutritional content of a recipe by passing all ingredients as a single query to API-Ninjas.\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"StorePreference\",\n",
        "        func=store_preference,\n",
        "        description=\"Store user preferences (e.g., allergies) in the vector database.\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"RetrievePreference\",\n",
        "        func=retrieve_preference,\n",
        "        description=\"Retrieve user preferences from the vector database with compression for relevance.\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"PrivateOnamRecipeSearch\",\n",
        "        func=retrieve_onam_recipe,\n",
        "        description=\"Search for Onam-specific private recipes using advanced RAG with compression.\"\n",
        "    )\n",
        "]\n",
        "\n",
        "# System Prompt\n",
        "system_prompt = \"\"\"\n",
        "You are a Chef Assistant designed to help users with culinary queries, focusing on recipes, nutritional analysis, and user preferences. Handle the following scenarios:\n",
        "1. **Recipe Search**: For non-Onam recipes, use RecipeSearch to fetch up to 3 recipes from TheMealDB API. For Onam-specific recipes, use PrivateOnamRecipeSearch to retrieve from the private vector store with advanced RAG compression.\n",
        "2. **Nutritional Analysis**: Use NutritionAnalysis to analyze the nutritional content of a recipe by passing all ingredients as a single query. If no ingredients are provided, extract them using ExtractIngredients first. Try to summarize and give a concise nutritional analysis.\n",
        "3. **User Preferences**: Always check user preferences via RetrievePreference before suggesting recipes. If a recipe contains ingredients that conflict with preferences (e.g., allergies), skip it or suggest an alternative by rewriting the recipe to exclude the conflicting ingredient(s).\n",
        "4. **Onam Recipes**: Store Onam-specific recipes using StoreOnamRecipe and retrieve them with PrivateOnamRecipeSearch. Ensure recipes are formatted with ingredients and instructions.\n",
        "5. **Multiple Results**: When multiple recipes are found, format them clearly, separated by '---'.\n",
        "6. **Error Handling**: If a tool fails or no results are found, provide a clear error message and suggest alternatives if possible. If a tool gives an error, try to rectify it.\n",
        "7. There might be diverse scenarios and you have to handle them accordingly.\n",
        "\n",
        "**Important**: If user preferences indicate allergies or dietary restrictions, avoid recipes with those ingredients. If a recipe contains a conflicting ingredient, rewrite it by substituting the ingredient (e.g., replace peanuts with almonds) or skip it and explain why. Always prioritize user safety and satisfaction.\n",
        "\"\"\"\n",
        "\n",
        "# Memory Setup\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "# Initialize Single Agent\n",
        "chef_agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        "    memory=memory,\n",
        "    handle_parsing_errors=True,\n",
        "    agent_kwargs={\"system_prompt\": system_prompt}\n",
        ")\n",
        "\n",
        "# Main Interaction Loop\n",
        "def main():\n",
        "    print(\"Welcome to the Chef Assistant!\")\n",
        "    print(\"Enter your query (e.g., 'Find Onam recipes and their nutritional value', 'Find chicken soup recipe and its nutritional value', 'I’m allergic to peanuts', 'Retrieve my family Onam payasam recipe') or 'exit' to quit.\")\n",
        "    while True:\n",
        "        user_input = input(\"Please enter your input: \")\n",
        "        if user_input.lower() == 'exit':\n",
        "            break\n",
        "        # Check preferences before processing\n",
        "        preferences = preference_retriever.get_relevant_documents(\"user preferences\")\n",
        "        preference_text = \"\\n\".join([doc.page_content for doc in preferences]) if preferences else \"\"\n",
        "        if preference_text:\n",
        "            user_input += f\" (Note: Consider user preferences (if relevant to the query) - {preference_text})\"\n",
        "        response = chef_agent.run(user_input)\n",
        "        print(response)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ebQmuMkXJBfU",
        "outputId": "2ca22937-ad01-46d9-e575-5c866172d567"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the Chef Assistant!\n",
            "Enter your query (e.g., 'Find Onam recipes and their nutritional value', 'Find chicken soup recipe and its nutritional value', 'I’m allergic to peanuts', 'Retrieve my family Onam payasam recipe') or 'exit' to quit.\n",
            "Please enter your input: Find chicken soup recipe and fetch its nutritonal value\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: RecipeSearch\n",
            "Action Input: chicken soup\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mRecipe: Rosol (Polish Chicken Soup)\n",
            "Ingredients: Chicken Legs, Onions, Carrots, Leek, Celery, Cabbage, Cloves, Allspice, Bay Leaf, Parsley, Dill, Pepper, Salt\n",
            "Instructions: Add chicken to a large Dutch oven or stock pot \n",
            "Cover with water\n",
            "Bring to a boil and simmer for 2 to 2 1/2 hours, skimming any impurities off the top to insure a clear broth\n",
            "If your pot is big enough, add the vegetables and spices for the last hour of the cooking time\n",
            "My Dutch oven wasn’t big enough to hold everything, just the chicken and other bones filled the pot, so I cooked the meat/bones for the full cooking time, then removed them, and cooked the vegetables and spices separately\n",
            "Strain everything out of the broth\n",
            "Bone the chicken, pulling the meat into large chunks\n",
            "Slice the carrots\n",
            "Return the chicken and carrots to the broth\n",
            "Cook noodles according to package instructions if you’re using them\n",
            "Add noodles to bowl and then top with hot soup\n",
            "\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mDo I need to use a tool? Yes\n",
            "Action: ExtractIngredients\n",
            "Action Input: Recipe: Rosol (Polish Chicken Soup)\n",
            "Ingredients: Chicken Legs, Onions, Carrots, Leek, Celery, Cabbage, Cloves, Allspice, Bay Leaf, Parsley, Dill, Pepper, Salt\n",
            "Instructions: Add chicken to a large Dutch oven or stock pot \n",
            "Cover with water\n",
            "Bring to a boil and simmer for 2 to 2 1/2 hours, skimming any impurities off the top to insure a clear broth\n",
            "If your pot is big enough, add the vegetables and spices for the last hour of the cooking time\n",
            "My Dutch oven wasn’t big enough to hold everything, just the chicken and other bones filled the pot, so I cooked the meat/bones for the full cooking time, then removed them, and cooked the vegetables and spices separately\n",
            "Strain everything out of the broth\n",
            "Bone the chicken, pulling the meat into large chunks\n",
            "Slice the carrots\n",
            "Return the chicken and carrots to the broth\n",
            "Cook noodles according to package instructions if you’re using them\n",
            "Add noodles to bowl and then top with hot soup\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mChicken Legs, Onions, Carrots, Leek, Celery, Cabbage, Cloves, Allspice, Bay Leaf, Parsley, Dill, Pepper, Salt\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mDo I need to use a tool? Yes\n",
            "Action: NutritionAnalysis\n",
            "Action Input: Chicken Legs, Onions, Carrots, Leek, Celery, Cabbage, Cloves, Allspice, Bay Leaf, Parsley, Dill, Pepper, Salt\u001b[0m\n",
            "Observation: \u001b[38;5;200m\u001b[1;3mFood: chicken legs\n",
            "Calories: Only available for premium subscribers. kcal\n",
            "Fat: 8.9g\n",
            "Protein: Only available for premium subscribers.g\n",
            "Carbs: 0.0g\n",
            "Food: onions\n",
            "Calories: Only available for premium subscribers. kcal\n",
            "Fat: 0.2g\n",
            "Protein: Only available for premium subscribers.g\n",
            "Carbs: 10.2g\n",
            "Food: carrots\n",
            "Calories: Only available for premium subscribers. kcal\n",
            "Fat: 0.2g\n",
            "Protein: Only available for premium subscribers.g\n",
            "Carbs: 8.1g\n",
            "Food: leek\n",
            "Calories: Only available for premium subscribers. kcal\n",
            "Fat: 0.2g\n",
            "Protein: Only available for premium subscribers.g\n",
            "Carbs: 7.6g\n",
            "Food: celery\n",
            "Calories: Only available for premium subscribers. kcal\n",
            "Fat: 0.2g\n",
            "Protein: Only available for premium subscribers.g\n",
            "Carbs: 4.0g\n",
            "Food: cabbage\n",
            "Calories: Only available for premium subscribers. kcal\n",
            "Fat: 0.1g\n",
            "Protein: Only available for premium subscribers.g\n",
            "Carbs: 5.5g\n",
            "Food: cloves\n",
            "Calories: Only available for premium subscribers. kcal\n",
            "Fat: 12.8g\n",
            "Protein: Only available for premium subscribers.g\n",
            "Carbs: 64.5g\n",
            "Food: allspice\n",
            "Calories: Only available for premium subscribers. kcal\n",
            "Fat: 8.9g\n",
            "Protein: Only available for premium subscribers.g\n",
            "Carbs: 72.3g\n",
            "Food: bay leaf\n",
            "Calories: Only available for premium subscribers. kcal\n",
            "Fat: 10.1g\n",
            "Protein: Only available for premium subscribers.g\n",
            "Carbs: 75.6g\n",
            "Food: parsley\n",
            "Calories: Only available for premium subscribers. kcal\n",
            "Fat: 0.8g\n",
            "Protein: Only available for premium subscribers.g\n",
            "Carbs: 6.2g\n",
            "Food: dill\n",
            "Calories: Only available for premium subscribers. kcal\n",
            "Fat: 1.0g\n",
            "Protein: Only available for premium subscribers.g\n",
            "Carbs: 7.1g\n",
            "Food: pepper\n",
            "Calories: Only available for premium subscribers. kcal\n",
            "Fat: 3.0g\n",
            "Protein: Only available for premium subscribers.g\n",
            "Carbs: 63.1g\n",
            "Food: salt\n",
            "Calories: Only available for premium subscribers. kcal\n",
            "Fat: 0.0g\n",
            "Protein: Only available for premium subscribers.g\n",
            "Carbs: 0.0g\n",
            "\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mDo I need to use a tool? No\n",
            "AI: Here is the recipe for Rosol (Polish Chicken Soup):\n",
            "\n",
            "**Ingredients:**\n",
            "Chicken Legs, Onions, Carrots, Leek, Celery, Cabbage, Cloves, Allspice, Bay Leaf, Parsley, Dill, Pepper, Salt\n",
            "\n",
            "**Instructions:**\n",
            "1. Add chicken to a large Dutch oven or stock pot.\n",
            "2. Cover with water.\n",
            "3. Bring to a boil and simmer for 2 to 2 1/2 hours, skimming any impurities off the top to insure a clear broth.\n",
            "4. If your pot is big enough, add the vegetables and spices for the last hour of the cooking time. (Note: If not, cook the meat/bones for the full cooking time, then remove them, and cook the vegetables and spices separately).\n",
            "5. Strain everything out of the broth.\n",
            "6. Bone the chicken, pulling the meat into large chunks.\n",
            "7. Slice the carrots.\n",
            "8. Return the chicken and carrots to the broth.\n",
            "9. Cook noodles according to package instructions if you’re using them.\n",
            "10. Add noodles to bowl and then top with hot soup.\n",
            "\n",
            "Here is the nutritional information for the ingredients (Note: Calories and Protein data are not available with the current access level):\n",
            "\n",
            "*   **Chicken Legs:** Fat: 8.9g, Carbs: 0.0g\n",
            "*   **Onions:** Fat: 0.2g, Carbs: 10.2g\n",
            "*   **Carrots:** Fat: 0.2g, Carbs: 8.1g\n",
            "*   **Leek:** Fat: 0.2g, Carbs: 7.6g\n",
            "*   **Celery:** Fat: 0.2g, Carbs: 4.0g\n",
            "*   **Cabbage:** Fat: 0.1g, Carbs: 5.5g\n",
            "*   **Cloves:** Fat: 12.8g, Carbs: 64.5g\n",
            "*   **Allspice:** Fat: 8.9g, Carbs: 72.3g\n",
            "*   **Bay Leaf:** Fat: 10.1g, Carbs: 75.6g\n",
            "*   **Parsley:** Fat: 0.8g, Carbs: 6.2g\n",
            "*   **Dill:** Fat: 1.0g, Carbs: 7.1g\n",
            "*   **Pepper:** Fat: 3.0g, Carbs: 63.1g\n",
            "*   **Salt:** Fat: 0.0g, Carbs: 0.0g\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Here is the recipe for Rosol (Polish Chicken Soup):\n",
            "\n",
            "**Ingredients:**\n",
            "Chicken Legs, Onions, Carrots, Leek, Celery, Cabbage, Cloves, Allspice, Bay Leaf, Parsley, Dill, Pepper, Salt\n",
            "\n",
            "**Instructions:**\n",
            "1. Add chicken to a large Dutch oven or stock pot.\n",
            "2. Cover with water.\n",
            "3. Bring to a boil and simmer for 2 to 2 1/2 hours, skimming any impurities off the top to insure a clear broth.\n",
            "4. If your pot is big enough, add the vegetables and spices for the last hour of the cooking time. (Note: If not, cook the meat/bones for the full cooking time, then remove them, and cook the vegetables and spices separately).\n",
            "5. Strain everything out of the broth.\n",
            "6. Bone the chicken, pulling the meat into large chunks.\n",
            "7. Slice the carrots.\n",
            "8. Return the chicken and carrots to the broth.\n",
            "9. Cook noodles according to package instructions if you’re using them.\n",
            "10. Add noodles to bowl and then top with hot soup.\n",
            "\n",
            "Here is the nutritional information for the ingredients (Note: Calories and Protein data are not available with the current access level):\n",
            "\n",
            "*   **Chicken Legs:** Fat: 8.9g, Carbs: 0.0g\n",
            "*   **Onions:** Fat: 0.2g, Carbs: 10.2g\n",
            "*   **Carrots:** Fat: 0.2g, Carbs: 8.1g\n",
            "*   **Leek:** Fat: 0.2g, Carbs: 7.6g\n",
            "*   **Celery:** Fat: 0.2g, Carbs: 4.0g\n",
            "*   **Cabbage:** Fat: 0.1g, Carbs: 5.5g\n",
            "*   **Cloves:** Fat: 12.8g, Carbs: 64.5g\n",
            "*   **Allspice:** Fat: 8.9g, Carbs: 72.3g\n",
            "*   **Bay Leaf:** Fat: 10.1g, Carbs: 75.6g\n",
            "*   **Parsley:** Fat: 0.8g, Carbs: 6.2g\n",
            "*   **Dill:** Fat: 1.0g, Carbs: 7.1g\n",
            "*   **Pepper:** Fat: 3.0g, Carbs: 63.1g\n",
            "*   **Salt:** Fat: 0.0g, Carbs: 0.0g\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-489737279.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-489737279.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter your query (e.g., 'Find Onam recipes and their nutritional value', 'Find chicken soup recipe and its nutritional value', 'I’m allergic to peanuts', 'Retrieve my family Onam payasam recipe') or 'exit' to quit.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Please enter your input: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'exit'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gXKDk3oruvCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import PyPDF2\n",
        "from langchain.agents import AgentType, initialize_agent\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.tools import Tool\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
        "from google.colab import userdata\n",
        "import uuid\n",
        "\n",
        "# Set up environment\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
        "os.environ[\"API_NINJAS_KEY\"] = userdata.get('API_NINJAS_KEY')\n",
        "\n",
        "# Initialize LLM\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
        "\n",
        "# Initialize embeddings for RAG and preferences\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "\n",
        "# Process PDF for Onam-specific private recipes\n",
        "def extract_text_from_pdf(pdf_path: str) -> str:\n",
        "    try:\n",
        "        with open(pdf_path, 'rb') as file:\n",
        "            reader = PyPDF2.PdfReader(file)\n",
        "            text = \"\"\n",
        "            for page in reader.pages:\n",
        "                text += page.extract_text() + \"\\n\"\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        return f\"Error extracting PDF: {str(e)}\"\n",
        "\n",
        "# Initialize FAISS vector store\n",
        "def create_vector_store(texts):\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "    chunks = text_splitter.split_text(\"\\n\".join(texts))\n",
        "    return FAISS.from_texts(chunks, embeddings)\n",
        "\n",
        "# Sample Onam recipes from PDF (replace with actual PDF path)\n",
        "pdf_path = \"/content/onam-recipes.pdf\"\n",
        "private_recipes_text = extract_text_from_pdf(pdf_path) if os.path.exists(pdf_path) else \"Error extracting PDF.\"\n",
        "\n",
        "# Initialize FAISS vector store with compression\n",
        "vector_store = create_vector_store([private_recipes_text])\n",
        "base_retriever = vector_store.as_retriever(search_kwargs={\"k\": 4, \"score_threshold\": 0.7})\n",
        "compressor = LLMChainExtractor.from_llm(llm)\n",
        "retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor,\n",
        "    base_retriever=base_retriever\n",
        ")\n",
        "\n",
        "# Initialize FAISS for user preferences with compression\n",
        "preferences_store = create_vector_store([\"No user preferences stored yet.\"])\n",
        "base_preference_retriever = preferences_store.as_retriever()\n",
        "preference_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor,\n",
        "    base_retriever=base_preference_retriever\n",
        ")\n",
        "\n",
        "# Tools\n",
        "def recipe_search(query: str) -> str:\n",
        "    \"\"\"Search for non-Onam recipes using TheMealDB API.\"\"\"\n",
        "    if \"onam\" in query.lower():\n",
        "        return \"Error: Onam recipes are available only through PrivateOnamRecipeSearch.\"\n",
        "    url = f\"https://www.themealdb.com/api/json/v1/1/search.php?s={query}\"\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        if data.get(\"meals\"):\n",
        "            results = []\n",
        "            preferences = preference_retriever.get_relevant_documents(\"user preferences\")\n",
        "            preference_text = \"\\n\".join([doc.page_content for doc in preferences]) if preferences else \"\"\n",
        "            for meal in data[\"meals\"][:3]:  # Limit to top 3 recipes\n",
        "                ingredients = [meal[f\"strIngredient{i}\"] for i in range(1, 21) if meal.get(f\"strIngredient{i}\") and meal[f\"strIngredient{i}\"].strip()]\n",
        "                for ingredient in ingredients:\n",
        "                    if preference_text and ingredient.lower() in preference_text.lower():\n",
        "                        return f\"Warning: Recipe '{meal['strMeal']}' contains {ingredient}, which conflicts with preferences: {preference_text}. Try another recipe.\"\n",
        "                results.append(f\"Recipe: {meal['strMeal']}\\nIngredients: {', '.join(ingredients)}\\nInstructions: {meal['strInstructions']}\\n\")\n",
        "            return \"\\n\".join(results) if results else \"No recipes found.\"\n",
        "        return \"No recipes found.\"\n",
        "    except requests.RequestException as e:\n",
        "        return f\"Error fetching recipe: {str(e)}\"\n",
        "\n",
        "def extract_ingredients(recipe: str) -> str:\n",
        "    \"\"\"Extract ingredients from a recipe string using LLM inference.\"\"\"\n",
        "    try:\n",
        "        prompt = f\"\"\"\n",
        "        Extract the ingredients from the following recipe text. If no explicit ingredient list is found, infer the ingredients based on the text and common culinary knowledge. Return a comma-separated list of ingredients or 'No ingredients found' if none can be identified.\n",
        "        Recipe: {recipe}\n",
        "        \"\"\"\n",
        "        result = llm.invoke(prompt).content.strip()\n",
        "        return result if result and \"No ingredients found\" not in result else \"No ingredients found.\"\n",
        "    except Exception:\n",
        "        return \"Error extracting ingredients.\"\n",
        "\n",
        "def nutrition_analysis(recipe: str) -> str:\n",
        "    \"\"\"Analyze nutritional content using API-Ninjas Nutrition API with full recipe description.\"\"\"\n",
        "    ingredients = extract_ingredients(recipe)\n",
        "    if \"No ingredients found\" in ingredients or \"Error\" in ingredients:\n",
        "        return \"Cannot analyze nutrition: No valid ingredients extracted.\"\n",
        "    api_key = userdata.get('API_NINJAS_KEY')\n",
        "    query = ingredients.replace(\", \", \" and \")  # Format for API\n",
        "    url = f\"https://api.api-ninjas.com/v1/nutrition?query={query}\"\n",
        "    try:\n",
        "        response = requests.get(url, headers={'X-Api-Key': api_key})\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        if data:\n",
        "            result = \"\"\n",
        "            for item in data:\n",
        "                result += f\"Food: {item['name']}\\nCalories: {item['calories']} kcal\\nFat: {item['fat_total_g']}g\\nProtein: {item['protein_g']}g\\nCarbs: {item['carbohydrates_total_g']}g\\n\"\n",
        "            return result\n",
        "        return \"No nutrition data found.\"\n",
        "    except requests.RequestException as e:\n",
        "        return f\"Error fetching nutrition data: {str(e)}\"\n",
        "\n",
        "def store_preference(preference: str) -> str:\n",
        "    \"\"\"Store user preference in the vector store.\"\"\"\n",
        "    preferences_store.add_texts([preference])\n",
        "    return \"Preference stored successfully.\"\n",
        "\n",
        "def retrieve_preference(query: str) -> str:\n",
        "    \"\"\"Retrieve user preferences from the vector store with compression.\"\"\"\n",
        "    results = preference_retriever.get_relevant_documents(query)\n",
        "    return \"\\n\".join([doc.page_content for doc in results]) if results else \"No preferences found.\"\n",
        "\n",
        "def store_onam_recipe(recipe: str) -> str:\n",
        "    \"\"\"Store an Onam-specific private recipe in the vector store.\"\"\"\n",
        "    if \"onam\" not in recipe.lower():\n",
        "        return \"Error: Only Onam-specific recipes can be stored.\"\n",
        "    vector_store.add_texts([recipe])\n",
        "    return \"Onam recipe stored successfully.\"\n",
        "\n",
        "def retrieve_onam_recipe(query: str) -> str:\n",
        "    \"\"\"Retrieve Onam-specific private recipes using advanced RAG with compression.\"\"\"\n",
        "    if \"onam\" not in query.lower():\n",
        "        query = \"Onam \" + query\n",
        "    results = retriever.get_relevant_documents(query)\n",
        "    if results:\n",
        "        combined_text = \"\\n\".join([doc.page_content for doc in results])\n",
        "        prompt = f\"\"\"\n",
        "        Format the following text into coherent Onam recipes with ingredients and instructions. If ingredients are missing, infer them based on the text and common Onam dishes (e.g., payasam, sambar, avial). Return in the format:\n",
        "        Recipe: [Name]\n",
        "        Ingredients: [Comma-separated list]\n",
        "        Instructions: [Steps]\n",
        "        If multiple recipes are identified, list them all, separated by '---'. If no recipe can be formed, return 'No Onam recipes found.'\n",
        "        Text: {combined_text}\n",
        "        \"\"\"\n",
        "        return llm.invoke(prompt).content.strip()\n",
        "    return \"No Onam recipes found.\"\n",
        "\n",
        "# Define Tools\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"RecipeSearch\",\n",
        "        func=recipe_search,\n",
        "        description=\"Search for non-Onam recipes using TheMealDB API. Returns up to 3 recipes.\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"ExtractIngredients\",\n",
        "        func=extract_ingredients,\n",
        "        description=\"Extract ingredients from a recipe string for further processing, using LLM inference for unstructured text.\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"NutritionAnalysis\",\n",
        "        func=nutrition_analysis,\n",
        "        description=\"Analyze nutritional content of a recipe by passing all ingredients as a single query to API-Ninjas.\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"StorePreference\",\n",
        "        func=store_preference,\n",
        "        description=\"Store user preferences (e.g., allergies) in the vector database.\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"RetrievePreference\",\n",
        "        func=retrieve_preference,\n",
        "        description=\"Retrieve user preferences from the vector database with compression for relevance.\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"PrivateOnamRecipeSearch\",\n",
        "        func=retrieve_onam_recipe,\n",
        "        description=\"Search for Onam-specific private recipes using advanced RAG with compression.\"\n",
        "    )\n",
        "]\n",
        "\n",
        "# System Prompt\n",
        "system_prompt = \"\"\"\n",
        "You are a Chef Assistant designed to help users with culinary queries, focusing on recipes, nutritional analysis, and user preferences. Handle the following scenarios:\n",
        "1. **Recipe Search**: For non-Onam recipes, use RecipeSearch to fetch up to 3 recipes from TheMealDB API. For Onam-specific recipes, use PrivateOnamRecipeSearch to retrieve from the private vector store with advanced RAG compression.\n",
        "2. **Nutritional Analysis**: Use NutritionAnalysis to analyze the nutritional content of a recipe by passing all ingredients as a single query. If no ingredients are provided, extract them using ExtractIngredients first. Try to summarize and give a concise nutritional analysis.\n",
        "3. **User Preferences**: Always check user preferences via RetrievePreference before suggesting recipes. If a recipe contains ingredients that conflict with preferences (e.g., allergies), skip it or suggest an alternative by rewriting the recipe to exclude the conflicting ingredient(s).\n",
        "4. **Onam Recipes**: Store Onam-specific recipes using StoreOnamRecipe and retrieve them with PrivateOnamRecipeSearch. Ensure recipes are formatted with ingredients and instructions.\n",
        "5. **Multiple Results**: When multiple recipes are found, format them clearly, separated by '---'.\n",
        "6. **Error Handling**: If a tool fails or no results are found, provide a clear error message and suggest alternatives if possible. If a tool gives an error, try to rectify it.\n",
        "7. There might be diverse scenarios and you have to handle them accordingly.\n",
        "8. If a partcular recipie is not found, search for the base recipie and make the modifications yourself. Use the tools to accomplish parts of the query.\n",
        "\n",
        "You may use nutritonal analysis tool to understand the nutrition of the recipie if the task directly or indirectly needs it.\n",
        "**Important**: If user preferences indicate allergies or dietary restrictions, avoid recipes with those ingredients. If a recipe contains a conflicting ingredient, rewrite it by substituting the ingredient (e.g., replace peanuts with almonds) or skip it and explain why. Always prioritize user safety and satisfaction.\n",
        "\"\"\"\n",
        "\n",
        "# Memory Setup\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "# Initialize Single Agent\n",
        "chef_agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        "    memory=memory,\n",
        "    handle_parsing_errors=True,\n",
        "    agent_kwargs={\"system_prompt\": system_prompt}\n",
        ")\n",
        "\n",
        "# Main Interaction Loop\n",
        "def main():\n",
        "    print(\"Welcome to the Chef Assistant!\")\n",
        "    print(\"Enter your query \\n\")\n",
        "    while True:\n",
        "        user_input = input(\"\\nPlease enter your input: \")\n",
        "        if user_input.lower() == 'exit':\n",
        "            break\n",
        "        # Check preferences before processing\n",
        "        preferences = preference_retriever.get_relevant_documents(\"user preferences\")\n",
        "        preference_text = \"\\n\".join([doc.page_content for doc in preferences]) if preferences else \"\"\n",
        "        if preference_text:\n",
        "            user_input += f\" (Note: Consider user preferences (if relevant to the query) - {preference_text})\"\n",
        "        response = chef_agent.run(user_input)\n",
        "        print(response)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "j8RpDEd7LUWT",
        "outputId": "f0b9dbce-7be6-4a73-d3da-ddec36f8fdc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the Chef Assistant!\n",
            "Enter your query \n",
            "\n",
            "\n",
            "Please enter your input: I have an allergy to raisins\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: StorePreference\n",
            "Action Input: allergy to raisins\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mPreference stored successfully.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mDo I need to use a tool? No\n",
            "AI: I've noted that you have an allergy to raisins. I will keep this in mind for future recipe suggestions.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "I've noted that you have an allergy to raisins. I will keep this in mind for future recipe suggestions.\n",
            "\n",
            "Please enter your input: Find me Onam payasam recipie that are low in carb and fat\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: PrivateOnamRecipeSearch\n",
            "Action Input: Onam payasam recipes low in carb and fat, excluding raisins\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.5-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 10\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 29\n",
            "}\n",
            "].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Observation: \u001b[38;5;200m\u001b[1;3mNo Onam recipes found.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mDo I need to use a tool? No\n",
            "AI: I couldn't find any Onam payasam recipes that are specifically low in carb and fat. Would you like me to look for other types of Onam recipes, or perhaps explore payasam recipes without the low carb and fat restriction?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "I couldn't find any Onam payasam recipes that are specifically low in carb and fat. Would you like me to look for other types of Onam recipes, or perhaps explore payasam recipes without the low carb and fat restriction?\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-763554182.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-763554182.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter your query \\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nPlease enter your input: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'exit'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langgraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-fwJPbcf3qV",
        "outputId": "340b882e-1c95-4277-f84c-6e74125424f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.6.3-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.72)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.6.3-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.0 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.2.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.11.7)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (0.4.8)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n",
            "  Downloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.3.0,>=0.2.0->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.3.0,>=0.2.0->langgraph) (3.11.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (0.23.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (1.3.1)\n",
            "Downloading langgraph-0.6.3-py3-none-any.whl (152 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.5/152.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.6.3-py3-none-any.whl (28 kB)\n",
            "Downloading langgraph_sdk-0.2.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
            "Successfully installed langgraph-0.6.3 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.6.3 langgraph-sdk-0.2.0 ormsgpack-1.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain_community langchain-google-genai faiss-cpu pypdf2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "Bg1CnwkKaZY4",
        "outputId": "f3c52e96-effa-41ab-88dd-2295d60a03ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.27)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.9-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.11.0.post1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting pypdf2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.72)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.12.14)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.29.5)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.14.1)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (3.11.1)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.7.14)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.74.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
            "Downloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_google_genai-2.1.9-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.11.0.post1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
            "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: filetype, python-dotenv, pypdf2, mypy-extensions, marshmallow, httpx-sse, faiss-cpu, typing-inspect, pydantic-settings, dataclasses-json, google-ai-generativelanguage, langchain-google-genai, langchain_community\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 faiss-cpu-1.11.0.post1 filetype-1.2.0 google-ai-generativelanguage-0.6.18 httpx-sse-0.4.1 langchain-google-genai-2.1.9 langchain_community-0.3.27 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.10.1 pypdf2-3.0.1 python-dotenv-1.1.1 typing-inspect-0.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "81d30f640b7d4745a4b862d802988d4c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import PyPDF2\n",
        "from langchain.agents import AgentType, initialize_agent\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.tools import Tool\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
        "from google.colab import userdata\n",
        "import uuid\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "# Set up environment\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
        "os.environ[\"API_NINJAS_KEY\"] = userdata.get('API_NINJAS_KEY')\n",
        "\n",
        "# Initialize LLM\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")\n",
        "\n",
        "# Initialize embeddings for RAG and preferences\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "\n",
        "# Process PDF for Onam-specific private recipes\n",
        "def extract_text_from_pdf(pdf_path: str) -> str:\n",
        "    try:\n",
        "        with open(pdf_path, 'rb') as file:\n",
        "            reader = PyPDF2.PdfReader(file)\n",
        "            text = \"\"\n",
        "            for page in reader.pages:\n",
        "                text += page.extract_text() + \"\\n\"\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        return f\"Error extracting PDF: {str(e)}\"\n",
        "\n",
        "# Initialize FAISS vector store\n",
        "def create_vector_store(texts: List[str]) -> FAISS:\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "    chunks = text_splitter.split_text(\"\\n\".join(texts))\n",
        "    return FAISS.from_texts(chunks, embeddings)\n",
        "\n",
        "# Sample Onam recipes from PDF (replace with actual PDF path)\n",
        "pdf_path = \"/content/onam-recipes.pdf\"\n",
        "private_recipes_text = extract_text_from_pdf(pdf_path) if os.path.exists(pdf_path) else \"Error extracting PDF.\"\n",
        "\n",
        "# Initialize FAISS vector store with compression\n",
        "vector_store = create_vector_store([private_recipes_text])\n",
        "base_retriever = vector_store.as_retriever(search_kwargs={\"k\": 4, \"score_threshold\": 0.7})\n",
        "compressor = LLMChainExtractor.from_llm(llm)\n",
        "retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor,\n",
        "    base_retriever=base_retriever\n",
        ")\n",
        "\n",
        "# Initialize FAISS for user preferences with compression\n",
        "preferences_store = create_vector_store([\"No user preferences stored yet.\"])\n",
        "base_preference_retriever = preferences_store.as_retriever()\n",
        "preference_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor,\n",
        "    base_retriever=base_preference_retriever\n",
        ")\n",
        "\n",
        "# Enhanced Tools\n",
        "def recipe_search(query: str) -> str:\n",
        "    \"\"\"Search for non-Onam recipes using TheMealDB API.\"\"\"\n",
        "    if \"onam\" in query.lower():\n",
        "        return \"Error: Onam recipes are available only through PrivateOnamRecipeSearch.\"\n",
        "    url = f\"https://www.themealdb.com/api/json/v1/1/search.php?s={query}\"\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        if data.get(\"meals\"):\n",
        "            results = []\n",
        "            for meal in data[\"meals\"][:3]:  # Limit to top 3 recipes\n",
        "                ingredients = [meal[f\"strIngredient{i}\"] for i in range(1, 21) if meal.get(f\"strIngredient{i}\") and meal[f\"strIngredient{i}\"].strip()]\n",
        "                results.append({\n",
        "                    \"name\": meal['strMeal'],\n",
        "                    \"ingredients\": ingredients,\n",
        "                    \"instructions\": meal['strInstructions']\n",
        "                })\n",
        "            return str(results)\n",
        "        return \"No recipes found.\"\n",
        "    except requests.RequestException as e:\n",
        "        return f\"Error fetching recipe: {str(e)}\"\n",
        "\n",
        "def extract_ingredients(recipe: str) -> str:\n",
        "    \"\"\"Extract ingredients from a recipe string using LLM inference.\"\"\"\n",
        "    try:\n",
        "        prompt = f\"\"\"\n",
        "        Extract the ingredients from the following recipe text. Return a JSON object with:\n",
        "        - \"ingredients\": list of ingredients\n",
        "        - \"possible_allergens\": list of common allergens found (e.g., nuts, dairy)\n",
        "        Recipe: {recipe}\n",
        "        \"\"\"\n",
        "        result = llm.invoke(prompt).content.strip()\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        return f\"Error extracting ingredients: {str(e)}\"\n",
        "\n",
        "def nutrition_analysis(recipe: str) -> str:\n",
        "    \"\"\"Analyze nutritional content using API-Ninjas Nutrition API.\"\"\"\n",
        "    try:\n",
        "        # First extract ingredients\n",
        "        ingredients_data = extract_ingredients(recipe)\n",
        "        if \"ingredients\" in ingredients_data:\n",
        "            ingredients = eval(ingredients_data)[\"ingredients\"]\n",
        "        else:\n",
        "            # Fallback to simple extraction if JSON parsing fails\n",
        "            prompt = f\"Extract just the ingredients from: {recipe}\"\n",
        "            ingredients = llm.invoke(prompt).content.split(\",\")\n",
        "\n",
        "        # Get nutrition data\n",
        "        api_key = userdata.get('API_NINJAS_KEY')\n",
        "        query = \" and \".join(ingredients[:10])  # Limit to 10 ingredients for API\n",
        "        url = f\"https://api.api-ninjas.com/v1/nutrition?query={query}\"\n",
        "        response = requests.get(url, headers={'X-Api-Key': api_key})\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "\n",
        "        # Calculate totals\n",
        "        totals = {\n",
        "            \"calories\": 0,\n",
        "            \"fat\": 0,\n",
        "            \"protein\": 0,\n",
        "            \"carbs\": 0\n",
        "        }\n",
        "        for item in data:\n",
        "            totals[\"calories\"] += item['calories']\n",
        "            totals[\"fat\"] += item['fat_total_g']\n",
        "            totals[\"protein\"] += item['protein_g']\n",
        "            totals[\"carbs\"] += item['carbohydrates_total_g']\n",
        "\n",
        "        return str({\n",
        "            \"per_serving\": totals,\n",
        "            \"details\": data\n",
        "        })\n",
        "    except Exception as e:\n",
        "        return f\"Error in nutrition analysis: {str(e)}\"\n",
        "\n",
        "def store_preference(preference: str) -> str:\n",
        "    \"\"\"Store user preference in the vector store.\"\"\"\n",
        "    preferences_store.add_texts([preference])\n",
        "    return \"Preference stored successfully.\"\n",
        "\n",
        "def retrieve_preference(query: str = \"\") -> str:\n",
        "    \"\"\"Retrieve all user preferences from the vector store.\"\"\"\n",
        "    results = preference_retriever.get_relevant_documents(\"user preferences\")\n",
        "    return str([doc.page_content for doc in results]) if results else \"No preferences found.\"\n",
        "\n",
        "def store_onam_recipe(recipe: str) -> str:\n",
        "    \"\"\"Store an Onam-specific private recipe in the vector store.\"\"\"\n",
        "    if \"onam\" not in recipe.lower():\n",
        "        return \"Error: Only Onam-specific recipes can be stored.\"\n",
        "    vector_store.add_texts([recipe])\n",
        "    return \"Onam recipe stored successfully.\"\n",
        "\n",
        "def retrieve_onam_recipe(query: str) -> str:\n",
        "    \"\"\"Retrieve Onam-specific private recipes using advanced RAG.\"\"\"\n",
        "    if \"onam\" not in query.lower():\n",
        "        query = \"Onam \" + query\n",
        "    results = retriever.get_relevant_documents(query)\n",
        "    return str([doc.page_content for doc in results]) if results else \"No Onam recipes found.\"\n",
        "\n",
        "def modify_recipe(recipe: str, modifications: str) -> str:\n",
        "    \"\"\"Modify a recipe based on requested changes.\"\"\"\n",
        "    try:\n",
        "        prompt = f\"\"\"\n",
        "        Modify the following recipe based on these requirements: {modifications}\n",
        "        Keep the core essence of the dish while making the requested changes.\n",
        "        Return the modified recipe in this format:\n",
        "        Name: [recipe name]\n",
        "        Ingredients: [list]\n",
        "        Instructions: [steps]\n",
        "        Modifications made: [summary]\n",
        "\n",
        "        Original recipe: {recipe}\n",
        "        \"\"\"\n",
        "        return llm.invoke(prompt).content\n",
        "    except Exception as e:\n",
        "        return f\"Error modifying recipe: {str(e)}\"\n",
        "\n",
        "# Define Enhanced Tools\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"RecipeSearch\",\n",
        "        func=recipe_search,\n",
        "        description=\"Search for non-Onam recipes from TheMealDB. Returns list of recipes with names, ingredients and instructions.\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"ExtractIngredients\",\n",
        "        func=extract_ingredients,\n",
        "        description=\"Extract ingredients and allergens from recipe text. Returns JSON with ingredients and possible allergens.\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"NutritionAnalysis\",\n",
        "        func=nutrition_analysis,\n",
        "        description=\"Analyze nutritional content of a recipe. Returns per-serving totals and detailed breakdown.\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"StorePreference\",\n",
        "        func=store_preference,\n",
        "        description=\"Store user dietary preferences/allergies in the vector database.\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"RetrievePreference\",\n",
        "        func=retrieve_preference,\n",
        "        description=\"Retrieve all stored user preferences from the vector database.\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"PrivateOnamRecipeSearch\",\n",
        "        func=retrieve_onam_recipe,\n",
        "        description=\"Search for Onam-specific private recipes from the vector store. Returns list of matching recipes.\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"ModifyRecipe\",\n",
        "        func=modify_recipe,\n",
        "        description=\"Modify a recipe to meet specific requirements (e.g., low carb, allergen-free). Returns adapted recipe.\"\n",
        "    )\n",
        "]\n",
        "\n",
        "# Enhanced System Prompt\n",
        "system_prompt = \"\"\"\n",
        "You are an Intelligent Chef Assistant with these capabilities:\n",
        "\n",
        "1. **Query Understanding**:\n",
        "   - Analyze the user's request to determine what they really need\n",
        "   - Identify implicit requirements (e.g., \"healthy\" = low fat/sugar)\n",
        "   - Consider context from conversation history\n",
        "\n",
        "2. **Tool Selection Strategy**:\n",
        "   - For Onam recipes: Use PrivateOnamRecipeSearch first\n",
        "   - For other recipes: Use RecipeSearch\n",
        "   - Always check preferences with RetrievePreference first\n",
        "   - For nutritional needs: Use NutritionAnalysis\n",
        "   - For modifications: Use ModifyRecipe\n",
        "\n",
        "3. **Preference Handling**:\n",
        "   - Before suggesting recipes, check for allergies/dietary restrictions\n",
        "   - If conflicts exist, either:\n",
        "     a) Find alternative recipes, or\n",
        "     b) Modify recipes to accommodate preferences using ModifyRecipe\n",
        "   - Clearly explain any modifications made\n",
        "\n",
        "4. **Nutritional Requests**:\n",
        "   - For \"healthy\", \"low carb\", etc. requests:\n",
        "     a) Find recipes that naturally fit, or\n",
        "     b) Modify existing recipes to meet criteria\n",
        "     c) Provide nutritional analysis to verify\n",
        "\n",
        "5. **Multi-Step Problem Solving**:\n",
        "   - Combine tools when needed (e.g., find recipe -> check nutrition -> modify if needed)\n",
        "   - Never give up after one tool fails - try alternative approaches\n",
        "\n",
        "6. **Response Formatting**:\n",
        "   - Present recipes clearly with name, ingredients, instructions\n",
        "   - Highlight modifications made\n",
        "   - Provide nutritional info when relevant\n",
        "   - Explain your reasoning for suggestions\n",
        "\n",
        "7. **Error Handling**:\n",
        "   - If tools fail, try alternative approaches\n",
        "   - Never say \"I couldn't find\" without trying all options\n",
        "   - If no perfect match exists, provide the closest option with modifications\n",
        "\n",
        "**Always** prioritize user preferences and dietary restrictions. Be proactive in finding solutions, not just reporting failures.\n",
        "\"\"\"\n",
        "\n",
        "# Memory Setup\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "# Initialize Enhanced Agent\n",
        "chef_agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        "    memory=memory,\n",
        "    handle_parsing_errors=True,\n",
        "    agent_kwargs={\n",
        "        \"system_prompt\": system_prompt,\n",
        "        \"prefix\": \"You are an expert chef assistant. Think step-by-step to provide the best culinary solutions.\"\n",
        "    }\n",
        ")\n",
        "\n",
        "# Enhanced Main Interaction Loop\n",
        "def main():\n",
        "    print(\"Welcome to the Enhanced Chef Assistant!\")\n",
        "    print(\"Type 'exit' to end the session.\\n\")\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            user_input = input(\"\\nYour culinary request: \").strip()\n",
        "            if user_input.lower() in ['exit', 'quit']:\n",
        "                break\n",
        "\n",
        "            if not user_input:\n",
        "                continue\n",
        "\n",
        "            # Get current preferences for context\n",
        "            prefs = retrieve_preference()\n",
        "            if prefs != \"No preferences found.\":\n",
        "                user_input += f\" (Current preferences: {prefs})\"\n",
        "\n",
        "            # Process the request\n",
        "            response = chef_agent.run({\n",
        "                \"input\": user_input,\n",
        "                \"chat_history\": memory.load_memory_variables({})['chat_history']\n",
        "            })\n",
        "\n",
        "            # Format the response\n",
        "            print(\"\\nChef Assistant:\")\n",
        "            print(response)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {str(e)}\")\n",
        "            print(\"Let's try that again. Please rephrase your request.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jxxYfT2Tm2AC",
        "outputId": "29de2ccf-9e46-409d-c988-e57b0d4a6cd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Welcome to the Enhanced Chef Assistant!\n",
            "Type 'exit' to end the session.\n",
            "\n",
            "\n",
            "Your culinary request: I am allergic to raisins\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
            "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 44\n",
            "}\n",
            "].\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
            "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 42\n",
            "}\n",
            "].\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            "violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
            "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 38\n",
            "}\n",
            "].\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1371075402.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-1371075402.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0;31m# Get current preferences for context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m             \u001b[0mprefs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretrieve_preference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprefs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"No preferences found.\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0muser_input\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\" (Current preferences: {prefs})\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1371075402.py\u001b[0m in \u001b[0;36mretrieve_preference\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mretrieve_preference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;34m\"\"\"Retrieve all user preferences from the vector store.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreference_retriever\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_relevant_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"user preferences\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_content\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"No preferences found.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawarning_emitting_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/retrievers.py\u001b[0m in \u001b[0;36mget_relevant_documents\u001b[0;34m(self, query, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"run_name\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.1.46\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malternative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ainvoke\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremoval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"1.0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/retrievers.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0mkwargs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expects_other_args\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_arg_supported\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m                 result = self._get_relevant_documents(\n\u001b[0m\u001b[1;32m    260\u001b[0m                     \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/retrievers/contextual_compression.py\u001b[0m in \u001b[0;36m_get_relevant_documents\u001b[0;34m(self, query, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m         )\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             compressed_docs = self.base_compressor.compress_documents(\n\u001b[0m\u001b[1;32m     47\u001b[0m                 \u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/retrievers/document_compressors/chain_extract.py\u001b[0m in \u001b[0;36mcompress_documents\u001b[0;34m(self, documents, query, callbacks)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0m_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0moutput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_chain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLLMChain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3044\u001b[0m                         \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3045\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3046\u001b[0;31m                         \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3047\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3048\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, code_execution, stop, **kwargs)\u001b[0m\n\u001b[1;32m   1486\u001b[0m                 )\n\u001b[1;32m   1487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1488\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1490\u001b[0m     def _get_ls_params(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m         return cast(\n\u001b[1;32m    394\u001b[0m             \u001b[0;34m\"ChatGeneration\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    396\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    978\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    979\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m                 results.append(\n\u001b[0;32m--> 799\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    800\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1043\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_from_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1045\u001b[0;31m             result = self._generate(\n\u001b[0m\u001b[1;32m   1046\u001b[0m                 \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[0m\n\u001b[1;32m   1593\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m         )\n\u001b[0;32m-> 1595\u001b[0;31m         response: GenerateContentResponse = _chat_with_retry(\n\u001b[0m\u001b[1;32m   1596\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_chat_with_retry\u001b[0;34m(generation_method, **kwargs)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32melse\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     )\n\u001b[0;32m--> 247\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_chat_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0mwrapped_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mretry_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mWrappedFn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoSleep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m                 \u001b[0mretry_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_for_next_attempt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdo\u001b[0m  \u001b[0;31m# type: ignore[no-any-return]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/nap.py\u001b[0m in \u001b[0;36msleep\u001b[0;34m(seconds)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mThis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmay\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mmocked\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0munit\u001b[0m \u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \"\"\"\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseconds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai langchain-openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuJWNQYWnOOh",
        "outputId": "77dbb962-b0d6-4440-85a0-a309094a8b04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.97.1)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.28-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.1)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.68 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.3.72)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (0.4.8)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (6.0.2)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.68->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-openai) (3.11.1)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-openai) (0.23.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.5.0)\n",
            "Downloading langchain_openai-0.3.28-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-openai\n",
            "Successfully installed langchain-openai-0.3.28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import PyPDF2\n",
        "from langchain.agents import AgentType, initialize_agent\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.tools import Tool\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from google.colab import userdata\n",
        "import uuid\n",
        "\n",
        "# Set up environment\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "os.environ[\"API_NINJAS_KEY\"] = userdata.get('API_NINJAS_KEY')\n",
        "\n",
        "# Initialize LLM - Replaced with GPT-4o\n",
        "#llm = ChatOpenAI(\n",
        "#    model=\"gpt-4o\",\n",
        "#    temperature=0,\n",
        "#    openai_api_key=os.environ[\"OPENAI_API_KEY\"]\n",
        "#)\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
        "os.environ[\"API_NINJAS_KEY\"] = userdata.get('API_NINJAS_KEY')\n",
        "\n",
        "# Initialize LLM\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
        "\n",
        "# Initialize embeddings (OpenAI)\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "\n",
        "# Process PDF for Onam-specific private recipes\n",
        "def extract_text_from_pdf(pdf_path: str) -> str:\n",
        "    try:\n",
        "        with open(pdf_path, 'rb') as file:\n",
        "            reader = PyPDF2.PdfReader(file)\n",
        "            text = \"\"\n",
        "            for page in reader.pages:\n",
        "                text += page.extract_text() + \"\\n\"\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        return f\"Error extracting PDF: {str(e)}\"\n",
        "\n",
        "# Initialize FAISS vector store\n",
        "def create_vector_store(texts):\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "    chunks = text_splitter.split_text(\"\\n\".join(texts))\n",
        "    return FAISS.from_texts(chunks, embeddings)\n",
        "\n",
        "# Sample Onam recipes from PDF (replace with actual PDF path)\n",
        "pdf_path = \"/content/onam-recipes.pdf\"\n",
        "private_recipes_text = extract_text_from_pdf(pdf_path) if os.path.exists(pdf_path) else \"Error extracting PDF.\"\n",
        "\n",
        "vector_store = create_vector_store([private_recipes_text])\n",
        "retriever = vector_store.as_retriever()\n",
        "\n",
        "# Initialize FAISS for user preferences\n",
        "preferences_store = create_vector_store([\"No user preferences stored yet.\"])\n",
        "preference_retriever = preferences_store.as_retriever()\n",
        "\n",
        "# Tools\n",
        "def recipe_search(query: str) -> str:\n",
        "    if \"onam\" in query.lower():\n",
        "        return \"Error: Onam recipes are available only through PrivateOnamRecipeSearch.\"\n",
        "    url = f\"https://www.themealdb.com/api/json/v1/1/search.php?s={query}\"\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        if data.get(\"meals\"):\n",
        "            results = []\n",
        "            preferences = preference_retriever.get_relevant_documents(\"user preferences\")\n",
        "            preference_text = \"\\n\".join([doc.page_content for doc in preferences]) if preferences else \"\"\n",
        "            for meal in data[\"meals\"][:3]:\n",
        "                ingredients = [meal[f\"strIngredient{i}\"] for i in range(1, 21) if meal.get(f\"strIngredient{i}\") and meal[f\"strIngredient{i}\"].strip()]\n",
        "                for ingredient in ingredients:\n",
        "                    if preference_text and ingredient.lower() in preference_text.lower():\n",
        "                        return f\"Warning: Recipe '{meal['strMeal']}' contains {ingredient}, which conflicts with preferences: {preference_text}. Try another recipe.\"\n",
        "                results.append(f\"Recipe: {meal['strMeal']}\\nIngredients: {', '.join(ingredients)}\\nInstructions: {meal['strInstructions']}\\n\")\n",
        "            return \"\\n\".join(results) if results else \"No recipes found.\"\n",
        "        return \"No recipes found.\"\n",
        "    except requests.RequestException as e:\n",
        "        return f\"Error fetching recipe: {str(e)}\"\n",
        "\n",
        "def extract_ingredients(recipe: str) -> str:\n",
        "    try:\n",
        "        prompt = f\"\"\"\n",
        "        Extract the ingredients from the following recipe text. If no explicit ingredient list is found, infer them based on the text and common culinary knowledge. Return a comma-separated list of ingredients or 'No ingredients found' if none can be identified.\n",
        "        Recipe: {recipe}\n",
        "        \"\"\"\n",
        "        result = llm.invoke(prompt).content.strip()\n",
        "        return result if result and \"No ingredients found\" not in result else \"No ingredients found.\"\n",
        "    except Exception:\n",
        "        return \"Error extracting ingredients.\"\n",
        "\n",
        "def nutrition_analysis(recipe: str) -> str:\n",
        "    ingredients = extract_ingredients(recipe)\n",
        "    if \"No ingredients found\" in ingredients or \"Error\" in ingredients:\n",
        "        return \"Cannot analyze nutrition: No valid ingredients extracted.\"\n",
        "    api_key = userdata.get('API_NINJAS_KEY')\n",
        "    query = ingredients.replace(\", \", \" and \")\n",
        "    url = f\"https://api.api-ninjas.com/v1/nutrition?query={query}\"\n",
        "    try:\n",
        "        response = requests.get(url, headers={'X-Api-Key': api_key})\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        if data:\n",
        "            result = \"\"\n",
        "            for item in data:\n",
        "                result += f\"Food: {item['name']}\\nCalories: {item['calories']} kcal\\nFat: {item['fat_total_g']}g\\nProtein: {item['protein_g']}g\\nCarbs: {item['carbohydrates_total_g']}g\\n\"\n",
        "            return result\n",
        "        return \"No nutrition data found.\"\n",
        "    except requests.RequestException as e:\n",
        "        return f\"Error fetching nutrition data: {str(e)}\"\n",
        "\n",
        "def store_preference(preference: str) -> str:\n",
        "    preferences_store.add_texts([preference])\n",
        "    return \"Preference stored successfully.\"\n",
        "\n",
        "def retrieve_preference(query: str) -> str:\n",
        "    results = preference_retriever.get_relevant_documents(query)\n",
        "    return \"\\n\".join([doc.page_content for doc in results]) if results else \"No preferences found.\"\n",
        "\n",
        "def store_onam_recipe(recipe: str) -> str:\n",
        "    if \"onam\" not in recipe.lower():\n",
        "        return \"Error: Only Onam-specific recipes can be stored.\"\n",
        "    vector_store.add_texts([recipe])\n",
        "    return \"Onam recipe stored successfully.\"\n",
        "\n",
        "def retrieve_onam_recipe(query: str) -> str:\n",
        "    if \"onam\" not in query.lower():\n",
        "        query = \"Onam \" + query\n",
        "    results = retriever.get_relevant_documents(query)\n",
        "    if results:\n",
        "        combined_text = \"\\n\".join([doc.page_content for doc in results])\n",
        "        prompt = f\"\"\"\n",
        "        Format the following text into coherent Onam recipes with ingredients and instructions. If ingredients are missing, infer them based on the text and common Onam dishes.\n",
        "        Return in the format:\n",
        "        Recipe: [Name]\n",
        "        Ingredients: [Comma-separated list]\n",
        "        Instructions: [Steps]\n",
        "        ---\n",
        "        If no recipe can be formed, return 'No Onam recipes found.'\n",
        "        Text: {combined_text}\n",
        "        \"\"\"\n",
        "        return llm.invoke(prompt).content.strip()\n",
        "    return \"No Onam recipes found.\"\n",
        "\n",
        "# Updated Tools with priority\n",
        "tools = [\n",
        "    Tool(name=\"RecipeSearch\", func=recipe_search, description=\"Primary: Search for non-Onam recipes using TheMealDB API.\"),\n",
        "    Tool(name=\"ExtractIngredients\", func=extract_ingredients, description=\"Extract ingredients from a recipe string.\"),\n",
        "    Tool(name=\"NutritionAnalysis\", func=nutrition_analysis, description=\"Primary: Analyze nutritional content of a recipe.\"),\n",
        "    Tool(name=\"StorePreference\", func=store_preference, description=\"Store user preferences (e.g., allergies) in the vector DB.\"),\n",
        "    Tool(name=\"RetrievePreference\", func=retrieve_preference, description=\"Retrieve user preferences from the vector DB.\"),\n",
        "    Tool(name=\"PrivateOnamRecipeSearch\", func=retrieve_onam_recipe, description=\"Search for Onam-specific recipes from private DB.\")\n",
        "]\n",
        "\n",
        "# Updated System Prompt to force tool-first approach\n",
        "system_prompt = \"\"\"\n",
        "You are a Chef Assistant specializing in recipes, nutrition, and dietary preferences.\n",
        "\n",
        "PRIORITY RULES:\n",
        "1. For any query about nutrition, calories, carbs, protein, fat, or similar — ALWAYS try the NutritionAnalysis tool first.\n",
        "2. For recipe searches — ALWAYS try RecipeSearch or PrivateOnamRecipeSearch before attempting to rewrite or guess recipes. try the NutritionAnalysis tool for nutritional info if needed in the query of the recipie.\n",
        "3. Only rewrite or modify recipes as a last resort if no results come from the tools.\n",
        "4. Check user preferences before suggesting recipes and avoid conflicting ingredients.\n",
        "5. For Onam recipes — store/retrieve using StoreOnamRecipe and PrivateOnamRecipeSearch.\n",
        "6. Return multiple recipes separated by '---'. Provide clear ingredient lists and steps.\n",
        "\"\"\"\n",
        "\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "chef_agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        "    memory=memory,\n",
        "    handle_parsing_errors=True,\n",
        "    agent_kwargs={\"system_prompt\": system_prompt}\n",
        ")\n",
        "\n",
        "def main():\n",
        "    print(\"Welcome to the Chef Assistant!\")\n",
        "    while True:\n",
        "        user_input = input(\"Enter your query (or 'exit' to quit): \")\n",
        "        if user_input.lower() == 'exit':\n",
        "            break\n",
        "        preferences = preference_retriever.get_relevant_documents(\"user preferences\")\n",
        "        preference_text = \"\\n\".join([doc.page_content for doc in preferences]) if preferences else \"\"\n",
        "        if preference_text:\n",
        "            user_input += f\" (Note: Consider user preferences - {preference_text})\"\n",
        "        response = chef_agent.run(user_input)\n",
        "        print(response)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioNacbxSuw6d",
        "outputId": "5decc877-9bad-4f3d-a8b8-9b51c7bc9ce5"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Welcome to the Chef Assistant!\n",
            "Enter your query (or 'exit' to quit): Find me a recipie for Onam Payasam. low carb and fat\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: PrivateOnamRecipeSearch\n",
            "Action Input: Onam Payasam, low carb, low fat\u001b[0m\n",
            "Observation: \u001b[38;5;200m\u001b[1;3mRecipe: Payasam\n",
            "Ingredients: Cooked Payasam (e.g., rice/vermicelli cooked with milk/jaggery), Crushed Cardamom, Ghee, Raisins, Cashew nuts.\n",
            "Instructions:\n",
            "1. Ensure the Payasam base is cooked to your desired consistency.\n",
            "2. Add crushed Cardamom and switch off from the stove.\n",
            "3. In a separate pan, melt Ghee and fry Raisins and Cashew nuts until golden.\n",
            "4. Pour the fried Raisins and Cashew nuts over the Payasam and serve.\n",
            "---\n",
            "Recipe: Coconut Milk Vegetable Curry\n",
            "Ingredients: Coconut Milk, Sautéed vegetables (e.g., pumpkin, ash gourd, cowpeas), Green Chillies, Curry Leaves, Salt, Coconut Oil.\n",
            "Instructions:\n",
            "1. (Assumed: Prepare and sauté your chosen vegetables and other ingredients on high flame until partially cooked).\n",
            "2. Add the sautéed ingredients along with Coconut Milk.\n",
            "3. Cook for about 4 minutes, ensuring not to let it boil, as Coconut Milk tends to split.\n",
            "4. The curry is now ready to be served.\n",
            "---\n",
            "Recipe: Kerala Style Curry (Final Touch)\n",
            "Ingredients: Cooked Curry (e.g., vegetable curry, lentil curry), Salt, Coconut oil.\n",
            "Instructions:\n",
            "1. (Assumed: Your curry is cooked and has been simmering for a few minutes, nearing completion).\n",
            "2. Adjust the Salt to taste if required.\n",
            "3. Ensure the curry does not boil vigorously at this stage.\n",
            "4. Pour Coconut oil over the curry, mix well, and remove from heat immediately.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mDo I need to use a tool? No\n",
            "AI: I found a recipe for \"Payasam\" which is an Onam dish. However, the recipe description mentions ingredients like \"rice/vermicelli cooked with milk/jaggery,\" \"Ghee,\" \"Raisins,\" and \"Cashew nuts.\" These ingredients are typically high in carbohydrates and fats, so this specific recipe may not align with your request for a low-carb and low-fat Onam Payasam.\n",
            "\n",
            "I was unable to find an Onam Payasam recipe that specifically meets both the low-carb and low-fat criteria in the available database.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "I found a recipe for \"Payasam\" which is an Onam dish. However, the recipe description mentions ingredients like \"rice/vermicelli cooked with milk/jaggery,\" \"Ghee,\" \"Raisins,\" and \"Cashew nuts.\" These ingredients are typically high in carbohydrates and fats, so this specific recipe may not align with your request for a low-carb and low-fat Onam Payasam.\n",
            "\n",
            "I was unable to find an Onam Payasam recipe that specifically meets both the low-carb and low-fat criteria in the available database.\n",
            "Enter your query (or 'exit' to quit): exit\n"
          ]
        }
      ]
    }
  ]
}